{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ascends'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d3dad460676f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mascends\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0masc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ascends'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ascends as asc\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding some more data for this particular example\n",
    "\n",
    "def add_reference_alloy_data(x_train, header_x, stress_key = 'Stress'):\n",
    "    \n",
    "    for i in range(0, len(header_x)):\n",
    "        if(header_x[i]==stress_key):\n",
    "            idx_of_stress = i\n",
    "    \n",
    "    # experimental code\n",
    "    x_train_update = []\n",
    "\n",
    "    y_1 = []\n",
    "    y_2 = []\n",
    "    \n",
    "    for i in range(0,len(x_train)):\n",
    "\n",
    "        x = x_train[i]\n",
    "        y = y_train[i][0]\n",
    "        Stress = x[idx_of_stress]\n",
    "\n",
    "        # data came fromTP347HFG-NF709, TP347HFG reference alloys\n",
    "        x_update = list(x)\n",
    "        if(Stress) ==70:\n",
    "            x_update+=[24563.25,24126]\n",
    "        elif(Stress) ==100:\n",
    "            x_update+=[23592,23174]\n",
    "        elif(Stress) ==130:\n",
    "            x_update+=[22812.5,22553]\n",
    "        elif(Stress) ==170:\n",
    "            x_update+=[22198,22050.5]\n",
    "        elif(Stress) ==200:\n",
    "            x_update+=[21612.5,21276]\n",
    "        elif(Stress) ==250:\n",
    "            x_update+=[20899.25,20562]\n",
    "        elif(Stress) ==300:\n",
    "            x_update+=[20317.75,19825.5]\n",
    "\n",
    "        if(x_update[-1]<y):\n",
    "            y_1.append([1])\n",
    "        else:\n",
    "            y_1.append([0])\n",
    "\n",
    "        if(x_update[-2]<y):\n",
    "            y_2.append([1])\n",
    "        else:\n",
    "            y_2.append([0])\n",
    "\n",
    "        x_train_update.append(x_update)\n",
    "\n",
    "    x_train_update = np.array(x_train_update)\n",
    "    x_train = x_train_update\n",
    "    y_1 = np.array(y_1)\n",
    "    y_2 = np.array(y_2)\n",
    "    \n",
    "    header_x = np.append(header_x, ['TP347HFG-NF709', 'TP347HFG'])\n",
    "\n",
    "    return x_train, header_x, y_1, y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scaler': 'MinMaxScaler', 'rf_n_estimators': '20', 'rf_max_features': 'sqrt', 'rf_max_depth': '110', 'rf_min_samples_split': '2', 'rf_min_samples_leaf': '1', 'rf_bootstrap': 'False', 'rf_criterion': 'mse', 'rf_min_weight_fraction_leaf': '0.', 'rf_max_leaf_nodes': 'None', 'rf_min_impurity_decrease': '0.', 'rf_min_impurity_split': '1e-7', 'rf_oob_score': 'False', 'nn_n_neighbors': '5', 'nn_weights': 'distance', 'nn_algorithm': 'kd_tree', 'nn_leaf_size': '77', 'nn_p': '1', 'nn_metric': 'minkowski', 'nn_metric_params': 'None', 'kr_alpha': '1', 'kr_kernel': 'linear', 'kr_gamma': 'sigmoid', 'kr_degree': '3', 'kr_coef0': '2', 'br_n_iter': '300', 'br_alpha_1': '1.2e-6', 'br_alpha_2': '1.e-7', 'br_tol': '0.01', 'br_lambda_1': '1.e-5', 'br_lambda_2': '1.e-7', 'br_compute_score': 'True', 'br_fit_intercept': 'True', 'br_normalize': 'False', 'svm_kernel': 'rbf', 'svm_degree': '3', 'svm_coef0': '3.0', 'svm_tol': '0.0056', 'svm_c': '3158', 'svm_epsilon': '0.1', 'svm_shrinking': 'True', 'svm_gamma': 'auto', 'svm_max_iter': '1'}\n"
     ]
    }
   ],
   "source": [
    "# Loading a config file from\n",
    "config_file = 'config/creep_more_features.properties'\n",
    "\n",
    "# Now all config parameters are set \n",
    "config, csv_file, cols_to_remove, target_col, scaler_option, path_to_mine_jar, \\\n",
    "output_dir, num_of_features, num_of_folds, num_of_sets, model_parameters = asc.load_cfg(config_file)\n",
    "\n",
    "print(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from csv file\n",
    "data_df, x_train, y_train, header_x, header_y = asc.data_load_shuffle(csv_file, None, cols_to_remove, target_col)\n",
    "\n",
    "# enrich data (optional), in this example, we added two more columns by using a custom function\n",
    "x_train, header_x, y_1, y_2 = add_reference_alloy_data(x_train, header_x, stress_key='Stress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Calculating MIC ..\n",
      "* Executing the following command: nohup java -jar lib/MINE.jar data/creep_more_features.csv 498 >MINE.log 2>&1&\n",
      "* Done\n",
      "\n",
      "* Calculating PCC ..\n",
      " - Pearson Correlation Coefficient [ output/corr_analysis.png ]\n",
      " - Pearson Correlation Coefficient (SQRT) [ output/corr_analysis.png ]\n",
      "* Done\n"
     ]
    }
   ],
   "source": [
    "# performing correlation analysis\n",
    "correlation_rank = asc.corr_analysis(data_df, target_col, csv_file, path_to_mine_jar, output_dir, show_charts=False, top_k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model_type = 'RF' # model type can be 'LR','RF','NN','KR','BR','SVM'\n",
    "model = asc.define_model_regression(model_type, num_of_features, model_parameters, x_header_size = x_train.shape[1])\n",
    "\n",
    "# Train and Predict\n",
    "predictions, actual_values = asc.train_and_predict(model, x_train, y_train, scaler_option, num_of_folds=num_of_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluation (k-fold cross validation)\n",
    "RMSE, R2 = asc.evaluate(predictions, actual_values)\n",
    "asc.show_comparison_chart(predictions, actual_values)\n",
    "print(\"* not tuned (%s)\\t RMSE = %8.3f, R2 = %8.3f\"%(model_type, RMSE, R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1680 candidates, totalling 8400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2343 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 8400 out of 8400 | elapsed:   10.6s finished\n"
     ]
    }
   ],
   "source": [
    "# tuning hyper parameters\n",
    "tuned_parameters = asc.hyperparameter_tuning(model_type, x_train, y_train\n",
    "                                             , num_of_folds, scaler_option\n",
    "                                           , n_iter=2000, random_state=0, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model training (with tuned parameters)\n",
    "model = asc.define_model_regression(model_type, num_of_features, model_parameters = tuned_parameters, x_header_size = x_train.shape[1])\n",
    "\n",
    "# Train and Predict\n",
    "predictions, actual_values = asc.train_and_predict(model, x_train, y_train, scaler_option, num_of_folds=num_of_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEKCAYAAABZr/GWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* tuned (KR)\t RMSE = 43152.663, R2 = -1972.554\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (k-fold cross validation) after hyperparameter tuning\n",
    "RMSE, R2 = asc.evaluate(predictions, actual_values)\n",
    "asc.show_comparison_chart(predictions, actual_values)\n",
    "print(\"* tuned (%s)\\t RMSE = %8.3f, R2 = %8.3f\"%(model_type, RMSE, R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training initiated ..\n",
      "* Training done.\n",
      "{'tag': 'KR-model-tuned-tag', 'model': Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectKBest(k=497, score_func=<function f_regression at 0x1a2c3b7d08>)), ('classification', KernelRidge(alpha=50.0, coef0=0.0, degree=1, gamma=None, kernel='linear',\n",
      "      kernel_params=None))]), 'model_abbr': 'KR', 'input_cols': array(['gs', 'dFCC', 'dFECR_B2', 'dL12', 'dLAVES_C14', 'dM23C6',\n",
      "       'dM2B_CB', 'dM3B2_D5A', 'dNbC', 'dNIAL_B2', 'dSIGMA', 'dT',\n",
      "       'Stress', 'T1', 'T1_DGM_NbC', 'T1_FCC_ACR_AL', 'T1_FCC_ACR_CR',\n",
      "       'T1_FCC_ACR_CU', 'T1_FCC_ACR_FE', 'T1_FCC_ACR_MN', 'T1_FCC_ACR_MO',\n",
      "       'T1_FCC_ACR_NB', 'T1_FCC_ACR_NI', 'T1_FCC_ACR_SI', 'T1_FCC_ACR_TI',\n",
      "       'T1_FCC_ACR_V', 'T1_FCC_ACR_W', 'T1_FCC_ACR_Y', 'T1_FCC_ACR_ZR',\n",
      "       'T1_FCC_CX_AL', 'T1_FCC_CX_B', 'T1_FCC_CX_C', 'T1_FCC_CX_CR',\n",
      "       'T1_FCC_CX_CU', 'T1_FCC_CX_FE', 'T1_FCC_CX_MN', 'T1_FCC_CX_MO',\n",
      "       'T1_FCC_CX_NB', 'T1_FCC_CX_NI', 'T1_FCC_CX_SI', 'T1_FCC_CX_TI',\n",
      "       'T1_FCC_CX_V', 'T1_FCC_CX_W', 'T1_FCC_CX_Y', 'T1_FCC_CX_ZR',\n",
      "       'T1_FCC_X_AL', 'T1_FCC_X_B', 'T1_FCC_X_C', 'T1_FCC_X_CR',\n",
      "       'T1_FCC_X_CU', 'T1_FCC_X_FE', 'T1_FCC_X_MN', 'T1_FCC_X_MO',\n",
      "       'T1_FCC_X_NB', 'T1_FCC_X_NI', 'T1_FCC_X_SI', 'T1_FCC_X_TI',\n",
      "       'T1_FCC_X_V', 'T1_FCC_X_W', 'T1_FCC_X_Y', 'T1_FCC_X_ZR',\n",
      "       'T1_L12_X_AL', 'T1_L12_X_B', 'T1_L12_X_C', 'T1_L12_X_CR',\n",
      "       'T1_L12_X_CU', 'T1_L12_X_FE', 'T1_L12_X_MN', 'T1_L12_X_MO',\n",
      "       'T1_L12_X_NB', 'T1_L12_X_NI', 'T1_L12_X_SI', 'T1_L12_X_TI',\n",
      "       'T1_L12_X_V', 'T1_L12_X_W', 'T1_L12_X_Y', 'T1_L12_X_ZR',\n",
      "       'T1_M23C6_CX_B', 'T1_M23C6_CX_C', 'T1_M23C6_CX_CR',\n",
      "       'T1_M23C6_CX_FE', 'T1_M23C6_CX_MN', 'T1_M23C6_CX_MO',\n",
      "       'T1_M23C6_CX_NI', 'T1_M23C6_CX_V', 'T1_M23C6_CX_W', 'T1_M23C6_X_B',\n",
      "       'T1_M23C6_X_C', 'T1_M23C6_X_CR', 'T1_M23C6_X_FE', 'T1_M23C6_X_MN',\n",
      "       'T1_M23C6_X_MO', 'T1_M23C6_X_NI', 'T1_M23C6_X_V', 'T1_M23C6_X_W',\n",
      "       'T1_M2B_CB_CX_B', 'T1_M2B_CB_CX_CR', 'T1_M2B_CB_CX_FE',\n",
      "       'T1_M2B_CB_CX_MN', 'T1_M2B_CB_CX_MO', 'T1_M2B_CB_CX_NI',\n",
      "       'T1_M2B_CB_X_B', 'T1_M2B_CB_X_CR', 'T1_M2B_CB_X_FE',\n",
      "       'T1_M2B_CB_X_MN', 'T1_M2B_CB_X_MO', 'T1_M2B_CB_X_NI',\n",
      "       'T1_M3B2_D5A_CX_B', 'T1_M3B2_D5A_CX_CR', 'T1_M3B2_D5A_CX_FE',\n",
      "       'T1_M3B2_D5A_CX_MO', 'T1_M3B2_D5A_CX_NI', 'T1_M3B2_D5A_CX_W',\n",
      "       'T1_M3B2_D5A_X_B', 'T1_M3B2_D5A_X_CR', 'T1_M3B2_D5A_X_FE',\n",
      "       'T1_M3B2_D5A_X_MO', 'T1_M3B2_D5A_X_NI', 'T1_M3B2_D5A_X_W',\n",
      "       'T1_NbC_ACR_AL', 'T1_NbC_ACR_CR', 'T1_NbC_ACR_CU', 'T1_NbC_ACR_FE',\n",
      "       'T1_NbC_ACR_MN', 'T1_NbC_ACR_MO', 'T1_NbC_ACR_NB', 'T1_NbC_ACR_NI',\n",
      "       'T1_NbC_ACR_SI', 'T1_NbC_ACR_TI', 'T1_NbC_ACR_V', 'T1_NbC_ACR_W',\n",
      "       'T1_NbC_ACR_Y', 'T1_NbC_ACR_ZR', 'T1_NbC_CX_AL', 'T1_NbC_CX_B',\n",
      "       'T1_NbC_CX_C', 'T1_NbC_CX_CR', 'T1_NbC_CX_CU', 'T1_NbC_CX_FE',\n",
      "       'T1_NbC_CX_MN', 'T1_NbC_CX_MO', 'T1_NbC_CX_NB', 'T1_NbC_CX_NI',\n",
      "       'T1_NbC_CX_SI', 'T1_NbC_CX_TI', 'T1_NbC_CX_V', 'T1_NbC_CX_W',\n",
      "       'T1_NbC_CX_Y', 'T1_NbC_CX_ZR', 'T1_NbC_X_AL', 'T1_NbC_X_B',\n",
      "       'T1_NbC_X_C', 'T1_NbC_X_CR', 'T1_NbC_X_CU', 'T1_NbC_X_FE',\n",
      "       'T1_NbC_X_MN', 'T1_NbC_X_MO', 'T1_NbC_X_NB', 'T1_NbC_X_NI',\n",
      "       'T1_NbC_X_SI', 'T1_NbC_X_TI', 'T1_NbC_X_V', 'T1_NbC_X_W',\n",
      "       'T1_NbC_X_Y', 'T1_NbC_X_ZR', 'T1_NIAL_B2_X_AL', 'T1_NIAL_B2_X_CR',\n",
      "       'T1_NIAL_B2_X_FE', 'T1_NIAL_B2_X_NI', 'T1_NP_FCC', 'T1_NP_L12',\n",
      "       'T1_NP_M23C6', 'T1_NP_M2B_CB', 'T1_NP_M3B2_D5A', 'T1_NP_NbC',\n",
      "       'T1_NP_NIAL_B2', 'T1_VPV_FCC', 'T1_VPV_FECR_B2', 'T1_VPV_L12',\n",
      "       'T1_VPV_LAVES_C14', 'T1_VPV_M23C6', 'T1_VPV_M2B_CB',\n",
      "       'T1_VPV_M3B2_D5A', 'T1_VPV_NbC', 'T1_VPV_NIAL_B2', 'T1_VPV_SIGMA',\n",
      "       'T2', 'T2_DGM_FECR_B2', 'T2_DGM_L12', 'T2_DGM_NbC',\n",
      "       'T2_DGM_NIAL_B2', 'T2_FCC_ACR_AL', 'T2_FCC_ACR_CR',\n",
      "       'T2_FCC_ACR_CU', 'T2_FCC_ACR_FE', 'T2_FCC_ACR_MN', 'T2_FCC_ACR_MO',\n",
      "       'T2_FCC_ACR_NB', 'T2_FCC_ACR_NI', 'T2_FCC_ACR_SI', 'T2_FCC_ACR_TI',\n",
      "       'T2_FCC_ACR_V', 'T2_FCC_ACR_W', 'T2_FCC_ACR_Y', 'T2_FCC_ACR_ZR',\n",
      "       'T2_FCC_CX_AL', 'T2_FCC_CX_B', 'T2_FCC_CX_C', 'T2_FCC_CX_CR',\n",
      "       'T2_FCC_CX_CU', 'T2_FCC_CX_FE', 'T2_FCC_CX_MN', 'T2_FCC_CX_MO',\n",
      "       'T2_FCC_CX_NB', 'T2_FCC_CX_NI', 'T2_FCC_CX_SI', 'T2_FCC_CX_TI',\n",
      "       'T2_FCC_CX_V', 'T2_FCC_CX_W', 'T2_FCC_CX_Y', 'T2_FCC_CX_ZR',\n",
      "       'T2_FCC_X_AL', 'T2_FCC_X_B', 'T2_FCC_X_C', 'T2_FCC_X_CR',\n",
      "       'T2_FCC_X_CU', 'T2_FCC_X_FE', 'T2_FCC_X_MN', 'T2_FCC_X_MO',\n",
      "       'T2_FCC_X_NB', 'T2_FCC_X_NI', 'T2_FCC_X_SI', 'T2_FCC_X_TI',\n",
      "       'T2_FCC_X_V', 'T2_FCC_X_W', 'T2_FCC_X_Y', 'T2_FCC_X_ZR',\n",
      "       'T2_FECR_ACR_B2_AL', 'T2_FECR_ACR_B2_CR', 'T2_FECR_ACR_B2_FE',\n",
      "       'T2_FECR_ACR_B2_NI', 'T2_FECR_B2_X_AL', 'T2_FECR_B2_X_CR',\n",
      "       'T2_FECR_B2_X_FE', 'T2_FECR_B2_X_NI', 'T2_FECR_CX_AL',\n",
      "       'T2_FECR_CX_CR', 'T2_FECR_CX_FE', 'T2_FECR_CX_NI', 'T2_L12_ACR_AL',\n",
      "       'T2_L12_ACR_CR', 'T2_L12_ACR_CU', 'T2_L12_ACR_FE', 'T2_L12_ACR_MN',\n",
      "       'T2_L12_ACR_MO', 'T2_L12_ACR_NB', 'T2_L12_ACR_NI', 'T2_L12_ACR_SI',\n",
      "       'T2_L12_ACR_TI', 'T2_L12_ACR_V', 'T2_L12_ACR_W', 'T2_L12_ACR_Y',\n",
      "       'T2_L12_ACR_ZR', 'T2_L12_CX_AL', 'T2_L12_CX_B', 'T2_L12_CX_C',\n",
      "       'T2_L12_CX_CR', 'T2_L12_CX_CU', 'T2_L12_CX_FE', 'T2_L12_CX_MN',\n",
      "       'T2_L12_CX_MO', 'T2_L12_CX_NB', 'T2_L12_CX_NI', 'T2_L12_CX_SI',\n",
      "       'T2_L12_CX_TI', 'T2_L12_CX_V', 'T2_L12_CX_W', 'T2_L12_CX_Y',\n",
      "       'T2_L12_CX_ZR', 'T2_L12_X_AL', 'T2_L12_X_B', 'T2_L12_X_C',\n",
      "       'T2_L12_X_CR', 'T2_L12_X_CU', 'T2_L12_X_FE', 'T2_L12_X_MN',\n",
      "       'T2_L12_X_MO', 'T2_L12_X_NB', 'T2_L12_X_NI', 'T2_L12_X_SI',\n",
      "       'T2_L12_X_TI', 'T2_L12_X_V', 'T2_L12_X_W', 'T2_L12_X_Y',\n",
      "       'T2_L12_X_ZR', 'T2_LAVES_C14_ACR_AL', 'T2_LAVES_C14_ACR_CR',\n",
      "       'T2_LAVES_C14_ACR_CU', 'T2_LAVES_C14_ACR_FE',\n",
      "       'T2_LAVES_C14_ACR_MN', 'T2_LAVES_C14_ACR_MO',\n",
      "       'T2_LAVES_C14_ACR_NB', 'T2_LAVES_C14_ACR_NI',\n",
      "       'T2_LAVES_C14_ACR_SI', 'T2_LAVES_C14_ACR_TI', 'T2_LAVES_C14_ACR_V',\n",
      "       'T2_LAVES_C14_ACR_W', 'T2_LAVES_C14_ACR_Y', 'T2_LAVES_C14_ACR_ZR',\n",
      "       'T2_LAVES_C14_CX_AL', 'T2_LAVES_C14_CX_CR', 'T2_LAVES_C14_CX_CU',\n",
      "       'T2_LAVES_C14_CX_FE', 'T2_LAVES_C14_CX_MN', 'T2_LAVES_C14_CX_MO',\n",
      "       'T2_LAVES_C14_CX_NB', 'T2_LAVES_C14_CX_NI', 'T2_LAVES_C14_CX_SI',\n",
      "       'T2_LAVES_C14_CX_TI', 'T2_LAVES_C14_CX_V', 'T2_LAVES_C14_CX_W',\n",
      "       'T2_LAVES_C14_CX_Y', 'T2_LAVES_C14_CX_ZR', 'T2_LAVES_C14_X_AL',\n",
      "       'T2_LAVES_C14_X_CR', 'T2_LAVES_C14_X_CU', 'T2_LAVES_C14_X_FE',\n",
      "       'T2_LAVES_C14_X_MN', 'T2_LAVES_C14_X_MO', 'T2_LAVES_C14_X_NB',\n",
      "       'T2_LAVES_C14_X_NI', 'T2_LAVES_C14_X_SI', 'T2_LAVES_C14_X_TI',\n",
      "       'T2_LAVES_C14_X_V', 'T2_LAVES_C14_X_W', 'T2_LAVES_C14_X_Y',\n",
      "       'T2_LAVES_C14_X_ZR', 'T2_M23C6_CX_B', 'T2_M23C6_CX_C',\n",
      "       'T2_M23C6_CX_CR', 'T2_M23C6_CX_FE', 'T2_M23C6_CX_MN',\n",
      "       'T2_M23C6_CX_MO', 'T2_M23C6_CX_NI', 'T2_M23C6_CX_V',\n",
      "       'T2_M23C6_CX_W', 'T2_M23C6_X_B', 'T2_M23C6_X_C', 'T2_M23C6_X_CR',\n",
      "       'T2_M23C6_X_FE', 'T2_M23C6_X_MN', 'T2_M23C6_X_MO', 'T2_M23C6_X_NI',\n",
      "       'T2_M23C6_X_V', 'T2_M23C6_X_W', 'T2_M2B_CB_CX_B',\n",
      "       'T2_M2B_CB_CX_CR', 'T2_M2B_CB_CX_FE', 'T2_M2B_CB_CX_MN',\n",
      "       'T2_M2B_CB_CX_MO', 'T2_M2B_CB_CX_NI', 'T2_M2B_CB_X_B',\n",
      "       'T2_M2B_CB_X_CR', 'T2_M2B_CB_X_FE', 'T2_M2B_CB_X_MN',\n",
      "       'T2_M2B_CB_X_MO', 'T2_M2B_CB_X_NI', 'T2_M3B2_D5A_CX_B',\n",
      "       'T2_M3B2_D5A_CX_CR', 'T2_M3B2_D5A_CX_FE', 'T2_M3B2_D5A_CX_MO',\n",
      "       'T2_M3B2_D5A_CX_NI', 'T2_M3B2_D5A_CX_W', 'T2_M3B2_D5A_X_B',\n",
      "       'T2_M3B2_D5A_X_CR', 'T2_M3B2_D5A_X_FE', 'T2_M3B2_D5A_X_MO',\n",
      "       'T2_M3B2_D5A_X_NI', 'T2_M3B2_D5A_X_W', 'T2_NbC_ACR_AL',\n",
      "       'T2_NbC_ACR_CR', 'T2_NbC_ACR_CU', 'T2_NbC_ACR_FE', 'T2_NbC_ACR_MN',\n",
      "       'T2_NbC_ACR_MO', 'T2_NbC_ACR_NB', 'T2_NbC_ACR_NI', 'T2_NbC_ACR_SI',\n",
      "       'T2_NbC_ACR_TI', 'T2_NbC_ACR_V', 'T2_NbC_ACR_W', 'T2_NbC_ACR_Y',\n",
      "       'T2_NbC_ACR_ZR', 'T2_NbC_CX_AL', 'T2_NbC_CX_B', 'T2_NbC_CX_C',\n",
      "       'T2_NbC_CX_CR', 'T2_NbC_CX_CU', 'T2_NbC_CX_FE', 'T2_NbC_CX_MN',\n",
      "       'T2_NbC_CX_MO', 'T2_NbC_CX_NB', 'T2_NbC_CX_NI', 'T2_NbC_CX_SI',\n",
      "       'T2_NbC_CX_TI', 'T2_NbC_CX_V', 'T2_NbC_CX_W', 'T2_NbC_CX_Y',\n",
      "       'T2_NbC_CX_ZR', 'T2_NbC_X_AL', 'T2_NbC_X_B', 'T2_NbC_X_C',\n",
      "       'T2_NbC_X_CR', 'T2_NbC_X_CU', 'T2_NbC_X_FE', 'T2_NbC_X_MN',\n",
      "       'T2_NbC_X_MO', 'T2_NbC_X_NB', 'T2_NbC_X_NI', 'T2_NbC_X_SI',\n",
      "       'T2_NbC_X_TI', 'T2_NbC_X_V', 'T2_NbC_X_W', 'T2_NbC_X_Y',\n",
      "       'T2_NbC_X_ZR', 'T2_NIAL_ACR_B2_AL', 'T2_NIAL_ACR_B2_CR',\n",
      "       'T2_NIAL_ACR_B2_FE', 'T2_NIAL_ACR_B2_NI', 'T2_NIAL_B2_X_AL',\n",
      "       'T2_NIAL_B2_X_CR', 'T2_NIAL_B2_X_FE', 'T2_NIAL_B2_X_NI',\n",
      "       'T2_NIAL_CX_AL', 'T2_NIAL_CX_CR', 'T2_NIAL_CX_FE', 'T2_NIAL_CX_NI',\n",
      "       'T2_NP_FCC', 'T2_NP_FECR_B2', 'T2_NP_L12', 'T2_NP_LAVES_C14',\n",
      "       'T2_NP_M23C6', 'T2_NP_M2B_CB', 'T2_NP_M3B2_D5A', 'T2_NP_NbC',\n",
      "       'T2_NP_NIAL_B2', 'T2_NP_SIGMA', 'T2_SIGMA_CX_AL', 'T2_SIGMA_CX_CR',\n",
      "       'T2_SIGMA_CX_FE', 'T2_SIGMA_CX_MN', 'T2_SIGMA_CX_MO',\n",
      "       'T2_SIGMA_CX_NB', 'T2_SIGMA_CX_NI', 'T2_SIGMA_CX_SI',\n",
      "       'T2_SIGMA_CX_TI', 'T2_SIGMA_CX_V', 'T2_SIGMA_CX_W',\n",
      "       'T2_SIGMA_X_AL', 'T2_SIGMA_X_CR', 'T2_SIGMA_X_FE', 'T2_SIGMA_X_MN',\n",
      "       'T2_SIGMA_X_MO', 'T2_SIGMA_X_NB', 'T2_SIGMA_X_NI', 'T2_SIGMA_X_SI',\n",
      "       'T2_SIGMA_X_TI', 'T2_SIGMA_X_V', 'T2_SIGMA_X_W', 'T2_VPV_FCC',\n",
      "       'T2_VPV_FECR_B2', 'T2_VPV_L12', 'T2_VPV_LAVES_C14', 'T2_VPV_M23C6',\n",
      "       'T2_VPV_M2B_CB', 'T2_VPV_M3B2_D5A', 'T2_VPV_NbC', 'T2_VPV_NIAL_B2',\n",
      "       'T2_VPV_SIGMA', 'xAL', 'xB', 'xC', 'xCR', 'xCU', 'xFE', 'xMN',\n",
      "       'xMO', 'xNB', 'xNI', 'xSI', 'xTI', 'xV', 'xW', 'xY', 'xZR', 'Nb_C',\n",
      "       'TP347HFG-NF709', 'TP347HFG'], dtype='<U19'), 'target_col': 'LMP', 'RMSE': 43152.66291252195, 'R2': -1972.5538143880594, 'fitted_scaler_x': StandardScaler(copy=True, with_mean=True, with_std=True)}\n",
      "* Trained model saved to file: ./KR-model-tuned-tag.pkl\n"
     ]
    }
   ],
   "source": [
    "# train and save\n",
    "model = asc.define_model_regression(model_type, num_of_features, model_parameters=tuned_parameters, x_header_size = x_train.shape[1])\n",
    "\n",
    "asc.train_and_save(model, model_type+'-model-tuned-tag', model_type\n",
    "                   , input_cols=header_x, target_col=header_y\n",
    "                   , x_train=x_train, y_train=y_train, scaler_option=scaler_option, path_to_save = '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   30.2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c520399a9933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     tuned_parameters = asc.hyperparameter_tuning(model_type, x_train, y_train\n\u001b[1;32m      5\u001b[0m                                              \u001b[0;34m,\u001b[0m \u001b[0mnum_of_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_option\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                              , n_iter=2000, random_state=0, verbose=1)\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# prediction with the tuned parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_model_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_header_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/slz/git_projects/ascends-toolkit/ascends.py\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(tag, x_train, y_train, num_of_folds, scaler_option, n_iter, random_state, verbose)\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0my_train_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0mtuned_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_key_to_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/slz/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/slz/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m/Users/slz/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/slz/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/slz/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/slz/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/slz/anaconda/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/slz/anaconda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning and show how it performs\n",
    "\n",
    "for model_type in ['RF','SVM','KR','BR','RF']:\n",
    "    tuned_parameters = asc.hyperparameter_tuning(model_type, x_train, y_train\n",
    "                                             , num_of_folds, scaler_option\n",
    "                                             , n_iter=2000, random_state=0, verbose=1)\n",
    "    # prediction with the tuned parameter\n",
    "    model = asc.define_model_regression(model_type, num_of_features, tuned_parameters, x_header_size = x_train.shape[1])\n",
    "    predictions, actual_values = asc.train_and_predict(model, x_train, y_train, scaler_option, num_of_folds=num_of_folds)\n",
    "    RMSE, R2 = asc.evaluate(predictions, actual_values)\n",
    "    print(\"* tuned (%s)\\t RMSE = %8.3f, R2 = %8.3f\"%(model_type, RMSE, R2))\n",
    "    asc.show_comparison_chart(predictions, actual_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "layer = 4\n",
    "params = [158, 1, 65, 179]\n",
    "dropout = 0.0119\n",
    "l_2 = 0.0481\n",
    "lr=0.000262\n",
    "epochs = 1000\n",
    "batch_size = 2\n",
    "num_of_folds = 5\n",
    "j = 0\n",
    "\n",
    "# Splitting the data for k-fold cross validation\n",
    "x_trains, y_trains, x_tests, y_tests = asc.split_data(x_train, y_train, num_of_folds=num_of_folds)\n",
    "\n",
    "# defining a model\n",
    "model = asc.net_define(params = params, layer_n = layer, input_size = x_trains[j].shape[1], dropout=dropout, l_2=l_2)\n",
    "model.summary()\n",
    "\n",
    "# choose your scaler\n",
    "scale = StandardScaler()\n",
    "x_train_ = scale.fit_transform(x_trains[j])\n",
    "\n",
    "# This is the change\n",
    "x_test_ = scale.transform(x_tests[j])\n",
    "\n",
    "# evaluating a model\n",
    "print('Training initiated ..')\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "score, history = asc.evaluate_net(model, epochs=epochs, batch_size=batch_size, x_train = x_train_, y_train = y_trains[0], x_test = x_test_, y_test = y_tests[0], verbose = 0, optimizer=optimizer)\n",
    "plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "plt.show()\n",
    "\n",
    "print('Model Test mean_absolute_percentage_error:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize the prediction\n",
    "asc.show_comparison_chart_model_x(model, x_test_, y_tests[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer = None\n",
    "params = None\n",
    "dropout = 0.0119\n",
    "l_2 = 0.0481\n",
    "lr = 0.000262\n",
    "epochs = 1000\n",
    "batch_size = 2\n",
    "num_of_folds = 5\n",
    "tries = 1000\n",
    "neuron_max = 256\n",
    "batch_size_max = 5\n",
    "layer_min = 4\n",
    "layer_max = 4\n",
    "dropout_max=0.02\n",
    "\n",
    "asc.net_tuning(tries = tries, lr = lr, x_trains = x_trains, y_trains = y_trains, x_tests = x_tests, y_tests = y_tests, layer = layer, params=params, epochs=epochs, batch_size=batch_size, dropout=dropout, l_2 = l_2, neuron_max=neuron_max, batch_size_max=batch_size_max, layer_min = layer_min, layer_max=layer_max, dropout_max=dropout_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
