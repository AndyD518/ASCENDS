{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header Check Function\n",
    "\n",
    "- The following function can be used to load header or to check what's in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_header(csv_file, print_out = False):\n",
    "    \n",
    "    # Loading headers\n",
    "    \n",
    "    headers = pd.read_csv(csv_file,header=None, nrows=1).values[0]\n",
    "    idx_to_key = {}\n",
    "    key_to_idx = {}\n",
    "    \n",
    "    for i in range(0, len(headers)):\n",
    "        idx = i\n",
    "        key = headers[i]\n",
    "        key_to_idx[key] = idx\n",
    "        idx_to_key[idx] = key\n",
    "    \n",
    "    if print_out is True:\n",
    "        print(idx_to_key)\n",
    "        \n",
    "    return headers, idx_to_key, key_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading Function\n",
    "\n",
    "- The following function loads csv file, remove unnecessary header, shuffle, and prepare data to be suitable for training\n",
    "- It also returns column names for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_load(csv_file, cols_to_remove, target_col, random_state=1):\n",
    "    \n",
    "    # Reading data in pandas dataframe and shuffle\n",
    "    \n",
    "    data = pd.read_csv(csv_file).values\n",
    "    data_df = pd.DataFrame(data)\n",
    "    data_df_shuffle = data_df.sample(frac=1, random_state=random_state)\n",
    "    \n",
    "    # splitting into input/output columns\n",
    "    \n",
    "    # last column is the target (LMP)\n",
    "    y_train = pd.DataFrame(data_df_shuffle[target_col])\n",
    "\n",
    "    # training set is without last column\n",
    "    data_df_shuffle.drop(data_df.columns[cols_to_remove+[target_col]],axis=1, inplace=True)\n",
    "    x_train = data_df_shuffle.copy()\n",
    "\n",
    "    # Loading headers\n",
    "    \n",
    "    headers, idx_to_key, key_to_idx = load_header(csv_file)\n",
    "        \n",
    "    cols_to_remove_ = []\n",
    "    headers = list(headers)\n",
    "    header_y = np.array([headers[target_col]])\n",
    "    for i in cols_to_remove:\n",
    "        headers.remove(idx_to_key[i])\n",
    "    \n",
    "    headers.remove(idx_to_key[target_col])\n",
    "        \n",
    "    # dataframe to numpy array\n",
    "    y_train = y_train.values\n",
    "    x_train = x_train.values\n",
    "\n",
    "    # reshaping target values\n",
    "    y_train = y_train.reshape(y_train.shape[0],1)\n",
    "\n",
    "    # set data types\n",
    "    x_train = x_train.astype('float32')\n",
    "    y_train = y_train.astype('float32')\n",
    "    header_x = np.array(headers)\n",
    "    \n",
    "    return data_df, x_train,y_train, header_x, header_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x_train, y_train, num_of_folds=5):\n",
    "    \n",
    "    num = x_train.shape[0]/int(num_of_folds)\n",
    "    x_train_parts = []\n",
    "    y_train_parts = []\n",
    "    for i in range(0,int(num_of_folds)):\n",
    "        start_idx = int(i*num+1) -1\n",
    "        end_idx = int(num*(i+1))\n",
    "        if i==int(num_of_folds)-1:\n",
    "            x_train_parts.append(x_train[start_idx:])\n",
    "            y_train_parts.append(y_train[start_idx:])\n",
    "        else:\n",
    "            x_train_parts.append(x_train[start_idx:end_idx])\n",
    "            y_train_parts.append(y_train[start_idx:end_idx])\n",
    "\n",
    "    x_trains = []\n",
    "    y_trains = []\n",
    "    x_tests = []\n",
    "    y_tests = []\n",
    "    \n",
    "    for i in range(0, num_of_folds):\n",
    "        x_test = x_train_parts[i]\n",
    "        y_test = y_train_parts[i]\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        for j in range(0, num_of_folds):\n",
    "            if j!=i:\n",
    "                x_train+=list(x_train_parts[j])\n",
    "                y_train+=list(y_train_parts[j])\n",
    "        \n",
    "        x_trains.append(np.array(x_train))\n",
    "        y_trains.append(np.array(y_train))\n",
    "        x_tests.append(np.array(x_test))\n",
    "        y_tests.append(np.array(y_test))\n",
    "        \n",
    "    return x_trains, y_trains, x_tests, y_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corr_analysis(data_df, idx_to_key, cols_to_remove, target_col):\n",
    "    corrcoefs = {}\n",
    "    corrcoefs_ = {}\n",
    "    for i in range(0,len(data_df.columns)):\n",
    "        if i not in cols_to_remove and i != target_col:\n",
    "            corrcoef = np.corrcoef(list(data_df[i].values),list(data_df[target_col].values))[0,1]\n",
    "            corrcoefs[idx_to_key[i]] = corrcoef\n",
    "\n",
    "    plt.bar(corrcoefs.keys(), corrcoefs.values(), width=0.8,color='g')\n",
    "    plt.show()\n",
    "\n",
    "    plt.bar(corrcoefs.keys(), [np.abs(i) for i in corrcoefs.values()], width=0.8,color='g')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for model definition and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_define(params = [8, 8, 8], layer_n = 3, input_size = 16, dropout=0, l_2=0.01):\n",
    "    \n",
    "    if len(params)!=layer_n or layer_n<1:\n",
    "        return None\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params[0], kernel_initializer='normal', activation='relu', input_dim=input_size, kernel_regularizer=regularizers.l2(l_2)))\n",
    "    \n",
    "    for i in range(1, layer_n):\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))\n",
    "        model.add(Dense(params[i], kernel_initializer='normal', activation='relu', kernel_regularizer=regularizers.l2(l_2)))\n",
    "    \n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def model_define_classifier(params = [8, 8, 8], layer_n = 3, input_size = 16, dropout=0, l_2=0.01):\n",
    "    \n",
    "    if len(params)!=layer_n or layer_n<1:\n",
    "        return None\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params[0], kernel_initializer='normal', activation='relu', input_dim=input_size, kernel_regularizer=regularizers.l2(l_2)))\n",
    "    \n",
    "    for i in range(1, layer_n):\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))\n",
    "        model.add(Dense(params[i], kernel_initializer='normal', activation='relu', kernel_regularizer=regularizers.l2(l_2)))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model_classifier(model, x_train, y_train, x_test, y_test, epochs=1000, batch_size=8, verbose = 0, optimizer = None):\n",
    "    if optimizer is None:\n",
    "        optimizer = 'adam'\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=verbose,\n",
    "                        validation_data=(x_test, y_test))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    return score, history\n",
    "\n",
    "def evaluate_model(model, x_train, y_train, x_test, y_test, epochs=1000, batch_size=8, verbose = 0, optimizer = None):\n",
    "    if optimizer is None:\n",
    "        optimizer = 'adam'\n",
    "    \n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=optimizer, metrics=['mape'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=verbose,\n",
    "                        validation_data=(x_test, y_test))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    return score, history\n",
    "\n",
    "def evaluate_model_classifier(model, x_train, y_train, x_test, y_test, epochs=1000, batch_size=8, verbose = 0, optimizer = None):\n",
    "    if optimizer is None:\n",
    "        optimizer = 'adam'\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=verbose,\n",
    "                        validation_data=(x_test, y_test))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    return score, history\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_tuning(x_trains, y_trains, x_tests, y_tests, tries = 10, lr = None, layer = None, params=None, epochs=None, batch_size=None, dropout=None, l_2 = None, neuron_max=64, batch_size_max=32, layer_min=1, layer_max=3, dropout_max=0.2):\n",
    "    \n",
    "    if layer is not None:\n",
    "        if layer<1:\n",
    "            print(\"layer must be >=1\")\n",
    "            return\n",
    "    \n",
    "    # Trying to tune hyperparameters\n",
    "    print(\" -- STARTED, don't panic and wait --\")\n",
    "\n",
    "    num_of_folds = len(x_trains)\n",
    "    \n",
    "    best_score = 100\n",
    "    best_params = None\n",
    "\n",
    "    _layer = layer\n",
    "    _params = params\n",
    "    _epochs = epochs\n",
    "    _batch_size = batch_size\n",
    "    _dropout = dropout\n",
    "    _l_2 = l_2\n",
    "    _neuron_max = neuron_max\n",
    "    _batch_size_max = batch_size_max\n",
    "    _dropout_max = dropout_max\n",
    "    _lr = lr\n",
    "    \n",
    "    for i in range(0, tries):\n",
    "\n",
    "        optimizer = 'adam'\n",
    "        \n",
    "        if lr is None:\n",
    "            lr = 10**np.random.uniform(-5,-3)\n",
    "            optimizer = keras.optimizers.Adam(lr=lr)\n",
    "                              \n",
    "        if layer is None:\n",
    "            layer = random.sample(range(layer_min, layer_max+1), 1)[0]\n",
    "\n",
    "        # selecting parameters\n",
    "        if params is None:\n",
    "            params = random.sample(range(1, neuron_max), layer)\n",
    "\n",
    "        if epochs is None:\n",
    "            epochs = int(10**np.random.uniform(2.7,3.7)) # 500 - 5000 \n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = random.sample(range(1, batch_size_max), 1)[0]\n",
    "\n",
    "        if dropout is None:\n",
    "            dropout = 0\n",
    "        elif dropout is True:\n",
    "            dropout = random.uniform(0,dropout_max)\n",
    "        else:\n",
    "            dropout = dropout\n",
    "\n",
    "        if l_2 is None:\n",
    "            l_2 = 10**np.random.uniform(-3,-1)\n",
    "\n",
    "        # defining model\n",
    "        scores = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        # the following two lines force params[0] to be 6-12 and j to be 0, remove this later\n",
    "        params[0] = random.sample(range(2, 13), 1)[0]\n",
    "        #params[1] = random.sample(range(167, 208), 1)[0]\n",
    "        #params[2] = random.sample(range(180, 221), 1)[0]\n",
    "        #params[3] = random.sample(range(86, 127), 1)[0]\n",
    "        \n",
    "        # params = [7, 187, 200, 106]\n",
    "        \n",
    "        #j = 0\n",
    "        \n",
    "        x_tests_ = []\n",
    "        models = []\n",
    "        \n",
    "        for j in range(1, num_of_folds):\n",
    "            \n",
    "            model = model_define(params=params, layer_n = layer, input_size = x_trains[j].shape[1], dropout=dropout, l_2=l_2)\n",
    "\n",
    "            # choose your scaler\n",
    "            scale = StandardScaler()\n",
    "            x_train_ = scale.fit_transform(x_trains[j])\n",
    "\n",
    "            # This is the change\n",
    "            x_test_ = scale.transform(x_tests[j])\n",
    "            x_tests_.append(x_test_)\n",
    "            #train and evaluate\n",
    "            start_time = time.time()\n",
    "            score, history = evaluate_model(model, epochs=epochs, batch_size=batch_size, x_train = x_train_, y_train = y_trains[j], x_test = x_test_, y_test = y_tests[j], verbose = 0, optimizer = optimizer)\n",
    "            scores.append(score[1])\n",
    "        \n",
    "            print(\"Iteration %d (fold:%d):\\t%s\\t%s\\t%s\\t%d\\t%8.5f\\t%8.3f\\t%8.3f\\tlr=%8.6f\"%(i, j, params, epochs, str(dropout), batch_size, l_2, score[1], (time.time() - start_time), lr))\n",
    "            if (score[1]>2.5):\n",
    "                break\n",
    "            models.append(model)\n",
    "            \n",
    "        avg_score = np.mean(scores)\n",
    "        print(\"average score = \", avg_score)\n",
    "        if(avg_score<best_score and len(models)==num_of_folds-1):            \n",
    "            best_score = avg_score\n",
    "            best_params = (layer, params, epochs, dropout, l_2, batch_size, lr)\n",
    "            #show_comparison_chart_all(models, x_tests_, y_tests)\n",
    "        \n",
    "        try:\n",
    "            print(\"best score = %8.3f\"%(best_score),\"[layer=%d, params=[%s], epochs=%d, dropout=%8.4f, l_2=%8.4f, batch_size=%d, lr=%8.6f]\"%best_params)\n",
    "        except:\n",
    "            print(\"best score attemped so far= %8.3f\"%(best_score))\n",
    "            print('still trying to find best settings ..')\n",
    "            \n",
    "        # set to original values\n",
    "        layer = _layer\n",
    "        params = _params\n",
    "        epochs = _epochs\n",
    "        batch_size = _batch_size\n",
    "        dropout = _dropout\n",
    "        l_2 = _l_2\n",
    "        neuron_max = _neuron_max\n",
    "        batch_size_max = _batch_size_max\n",
    "        dropout_max = _dropout_max\n",
    "        lr = _lr\n",
    "        \n",
    "    print(\" -- DONE --\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hp_tuning_classification(x_trains, y_trains, x_tests, y_tests, tries = 10, lr = None, layer = None, params=None, epochs=None, batch_size=None, dropout=None, l_2 = None, neuron_max=64, batch_size_max=32, layer_min=1, layer_max=3, dropout_max=0.2):\n",
    "    \n",
    "    if layer is not None:\n",
    "        if layer<1:\n",
    "            print(\"layer must be >=1\")\n",
    "            return\n",
    "    \n",
    "    # Trying to tune hyperparameters\n",
    "    print(\" -- STARTED, don't panic and wait --\")\n",
    "\n",
    "    num_of_folds = len(x_trains)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    _layer = layer\n",
    "    _params = params\n",
    "    _epochs = epochs\n",
    "    _batch_size = batch_size\n",
    "    _dropout = dropout\n",
    "    _l_2 = l_2\n",
    "    _neuron_max = neuron_max\n",
    "    _batch_size_max = batch_size_max\n",
    "    _dropout_max = dropout_max\n",
    "    _lr = lr\n",
    "    \n",
    "    for i in range(0, tries):\n",
    "\n",
    "        optimizer = 'adam'\n",
    "        \n",
    "        if lr is None:\n",
    "            lr = 10**np.random.uniform(-5,-3)\n",
    "            optimizer = keras.optimizers.Adam(lr=lr)\n",
    "                              \n",
    "        if layer is None:\n",
    "            layer = random.sample(range(layer_min, layer_max+1), 1)[0]\n",
    "\n",
    "        # selecting parameters\n",
    "        if params is None:\n",
    "            params = random.sample(range(1, neuron_max), layer)\n",
    "\n",
    "        if epochs is None:\n",
    "            epochs = int(10**np.random.uniform(2.7,3.7)) # 500 - 5000 \n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = random.sample(range(1, batch_size_max), 1)[0]\n",
    "\n",
    "        if dropout is None:\n",
    "            dropout = 0\n",
    "        elif dropout is True:\n",
    "            dropout = random.uniform(0,dropout_max)\n",
    "        else:\n",
    "            dropout = dropout\n",
    "\n",
    "        if l_2 is None:\n",
    "            l_2 = 10**np.random.uniform(-3,-1)\n",
    "\n",
    "        # defining model\n",
    "        scores = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        # the following two lines force params[0] to be 6-12 and j to be 0, remove this later\n",
    "        # params[0] = random.sample(range(2, 13), 1)[0]\n",
    "        #params[1] = random.sample(range(167, 208), 1)[0]\n",
    "        #params[2] = random.sample(range(180, 221), 1)[0]\n",
    "        #params[3] = random.sample(range(86, 127), 1)[0]\n",
    "        \n",
    "        # params = [7, 187, 200, 106]\n",
    "        \n",
    "        #j = 0\n",
    "        \n",
    "        x_tests_ = []\n",
    "        models = []\n",
    "        \n",
    "        for j in range(1, num_of_folds):\n",
    "            \n",
    "            model = model_define_classifier(params=params, layer_n = layer, input_size = x_trains[j].shape[1], dropout=dropout, l_2=l_2)\n",
    "            \n",
    "            # choose your scaler\n",
    "            scale = StandardScaler()\n",
    "            x_train_ = scale.fit_transform(x_trains[j])\n",
    "\n",
    "            # This is the change\n",
    "            x_test_ = scale.transform(x_tests[j])\n",
    "            x_tests_.append(x_test_)\n",
    "            #train and evaluate\n",
    "            start_time = time.time()\n",
    "            score, history = evaluate_model_classifier(model, epochs=epochs, batch_size=batch_size, x_train = x_train_, y_train = y_trains[j], x_test = x_test_, y_test = y_tests[j], verbose = 0, optimizer = optimizer)\n",
    "            #print(score)\n",
    "            scores.append(score[1])\n",
    "        \n",
    "            print(\"Iteration %d (fold:%d):\\t%s\\t%s\\t%s\\t%d\\t%8.5f\\t%8.3f\\t%8.3f\\tlr=%8.6f\"%(i, j, params, epochs, str(dropout), batch_size, l_2, score[1], (time.time() - start_time), lr))\n",
    "            if (score[1]<0.70):\n",
    "                break\n",
    "            models.append(model)\n",
    "            \n",
    "        avg_score = np.mean(scores)\n",
    "        print(\"average score = \", avg_score)\n",
    "        if(avg_score>best_score and len(models)==num_of_folds-1):            \n",
    "            best_score = avg_score\n",
    "            best_params = (layer, params, epochs, dropout, l_2, batch_size, lr)\n",
    "            #show_comparison_chart_all(models, x_tests_, y_tests)\n",
    "            \n",
    "       \n",
    "        try:\n",
    "            print(\"best score = %8.3f\"%(best_score),\"[layer=%d, params=[%s], epochs=%d, dropout=%8.4f, l_2=%8.4f, batch_size=%d, lr=%8.6f]\"%best_params)\n",
    "        except:\n",
    "            print(\"best score attemped so far= %8.3f\"%(best_score))\n",
    "            print('still trying to find best settings ..')\n",
    "            \n",
    "        # set to original values\n",
    "        layer = _layer\n",
    "        params = _params\n",
    "        epochs = _epochs\n",
    "        batch_size = _batch_size\n",
    "        dropout = _dropout\n",
    "        l_2 = _l_2\n",
    "        neuron_max = _neuron_max\n",
    "        batch_size_max = _batch_size_max\n",
    "        dropout_max = _dropout_max\n",
    "        lr = _lr\n",
    "        \n",
    "    print(\" -- DONE --\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comparison_chart(model, x_test, y_test):\n",
    "    min_val = min(y_test)\n",
    "    max_val = max(y_test)\n",
    "\n",
    "    plt.xlabel('Predicted Value')\n",
    "    plt.ylabel('Actual Value')\n",
    "    plt.ylim([min_val, max_val])\n",
    "    plt.xlim([min_val, max_val])\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.scatter(model.predict(x_test),y_test)\n",
    "    t = np.arange(min_val, max_val, 0.01)\n",
    "    line, = plt.plot(t, t, lw=1)\n",
    "    plt.show()\n",
    "\n",
    "def show_comparison_chart_all(models, x_tests, y_tests):\n",
    "    min_val = min(y_tests[0])*0.95\n",
    "    max_val = max(y_tests[0])*1.05\n",
    "\n",
    "    plt.xlabel('Predicted Value')\n",
    "    plt.ylabel('Actual Value')\n",
    "    plt.ylim([min_val, max_val])\n",
    "    plt.xlim([min_val, max_val])\n",
    "    plt.grid(True)\n",
    "    t = np.arange(min_val, max_val, 0.01)\n",
    "    line, = plt.plot(t, t, lw=1)\n",
    "    \n",
    "    for j in range(0, num_of_folds):\n",
    "        plt.scatter(models[j].predict(x_tests[j]),y_tests[j])\n",
    "        \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis starts from here\n",
    "- Performing various analysis using the functions defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To decide which columns are used for input/target, and to decide which columns to remove\n",
    "\n",
    "file_to_load = 'creep_more_features.csv'\n",
    "headers, idx_to_key, key_to_idx = load_header(file_to_load)\n",
    "#print(idx_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Column Names: ['gs' 'dFCC' 'dFECR_B2' 'dL12' 'dLAVES_C14' 'dM23C6' 'dM2B_CB' 'dM3B2_D5A'\n",
      " 'dNbC' 'dNIAL_B2' 'dSIGMA' 'dT' 'Stress' 'T1' 'T1_DGM_NbC'\n",
      " 'T1_FCC_ACR_AL' 'T1_FCC_ACR_CR' 'T1_FCC_ACR_CU' 'T1_FCC_ACR_FE'\n",
      " 'T1_FCC_ACR_MN' 'T1_FCC_ACR_MO' 'T1_FCC_ACR_NB' 'T1_FCC_ACR_NI'\n",
      " 'T1_FCC_ACR_SI' 'T1_FCC_ACR_TI' 'T1_FCC_ACR_V' 'T1_FCC_ACR_W'\n",
      " 'T1_FCC_ACR_Y' 'T1_FCC_ACR_ZR' 'T1_FCC_CX_AL' 'T1_FCC_CX_B' 'T1_FCC_CX_C'\n",
      " 'T1_FCC_CX_CR' 'T1_FCC_CX_CU' 'T1_FCC_CX_FE' 'T1_FCC_CX_MN'\n",
      " 'T1_FCC_CX_MO' 'T1_FCC_CX_NB' 'T1_FCC_CX_NI' 'T1_FCC_CX_SI'\n",
      " 'T1_FCC_CX_TI' 'T1_FCC_CX_V' 'T1_FCC_CX_W' 'T1_FCC_CX_Y' 'T1_FCC_CX_ZR'\n",
      " 'T1_FCC_X_AL' 'T1_FCC_X_B' 'T1_FCC_X_C' 'T1_FCC_X_CR' 'T1_FCC_X_CU'\n",
      " 'T1_FCC_X_FE' 'T1_FCC_X_MN' 'T1_FCC_X_MO' 'T1_FCC_X_NB' 'T1_FCC_X_NI'\n",
      " 'T1_FCC_X_SI' 'T1_FCC_X_TI' 'T1_FCC_X_V' 'T1_FCC_X_W' 'T1_FCC_X_Y'\n",
      " 'T1_FCC_X_ZR' 'T1_L12_X_AL' 'T1_L12_X_B' 'T1_L12_X_C' 'T1_L12_X_CR'\n",
      " 'T1_L12_X_CU' 'T1_L12_X_FE' 'T1_L12_X_MN' 'T1_L12_X_MO' 'T1_L12_X_NB'\n",
      " 'T1_L12_X_NI' 'T1_L12_X_SI' 'T1_L12_X_TI' 'T1_L12_X_V' 'T1_L12_X_W'\n",
      " 'T1_L12_X_Y' 'T1_L12_X_ZR' 'T1_M23C6_CX_B' 'T1_M23C6_CX_C'\n",
      " 'T1_M23C6_CX_CR' 'T1_M23C6_CX_FE' 'T1_M23C6_CX_MN' 'T1_M23C6_CX_MO'\n",
      " 'T1_M23C6_CX_NI' 'T1_M23C6_CX_V' 'T1_M23C6_CX_W' 'T1_M23C6_X_B'\n",
      " 'T1_M23C6_X_C' 'T1_M23C6_X_CR' 'T1_M23C6_X_FE' 'T1_M23C6_X_MN'\n",
      " 'T1_M23C6_X_MO' 'T1_M23C6_X_NI' 'T1_M23C6_X_V' 'T1_M23C6_X_W'\n",
      " 'T1_M2B_CB_CX_B' 'T1_M2B_CB_CX_CR' 'T1_M2B_CB_CX_FE' 'T1_M2B_CB_CX_MN'\n",
      " 'T1_M2B_CB_CX_MO' 'T1_M2B_CB_CX_NI' 'T1_M2B_CB_X_B' 'T1_M2B_CB_X_CR'\n",
      " 'T1_M2B_CB_X_FE' 'T1_M2B_CB_X_MN' 'T1_M2B_CB_X_MO' 'T1_M2B_CB_X_NI'\n",
      " 'T1_M3B2_D5A_CX_B' 'T1_M3B2_D5A_CX_CR' 'T1_M3B2_D5A_CX_FE'\n",
      " 'T1_M3B2_D5A_CX_MO' 'T1_M3B2_D5A_CX_NI' 'T1_M3B2_D5A_CX_W'\n",
      " 'T1_M3B2_D5A_X_B' 'T1_M3B2_D5A_X_CR' 'T1_M3B2_D5A_X_FE'\n",
      " 'T1_M3B2_D5A_X_MO' 'T1_M3B2_D5A_X_NI' 'T1_M3B2_D5A_X_W' 'T1_NbC_ACR_AL'\n",
      " 'T1_NbC_ACR_CR' 'T1_NbC_ACR_CU' 'T1_NbC_ACR_FE' 'T1_NbC_ACR_MN'\n",
      " 'T1_NbC_ACR_MO' 'T1_NbC_ACR_NB' 'T1_NbC_ACR_NI' 'T1_NbC_ACR_SI'\n",
      " 'T1_NbC_ACR_TI' 'T1_NbC_ACR_V' 'T1_NbC_ACR_W' 'T1_NbC_ACR_Y'\n",
      " 'T1_NbC_ACR_ZR' 'T1_NbC_CX_AL' 'T1_NbC_CX_B' 'T1_NbC_CX_C' 'T1_NbC_CX_CR'\n",
      " 'T1_NbC_CX_CU' 'T1_NbC_CX_FE' 'T1_NbC_CX_MN' 'T1_NbC_CX_MO'\n",
      " 'T1_NbC_CX_NB' 'T1_NbC_CX_NI' 'T1_NbC_CX_SI' 'T1_NbC_CX_TI' 'T1_NbC_CX_V'\n",
      " 'T1_NbC_CX_W' 'T1_NbC_CX_Y' 'T1_NbC_CX_ZR' 'T1_NbC_X_AL' 'T1_NbC_X_B'\n",
      " 'T1_NbC_X_C' 'T1_NbC_X_CR' 'T1_NbC_X_CU' 'T1_NbC_X_FE' 'T1_NbC_X_MN'\n",
      " 'T1_NbC_X_MO' 'T1_NbC_X_NB' 'T1_NbC_X_NI' 'T1_NbC_X_SI' 'T1_NbC_X_TI'\n",
      " 'T1_NbC_X_V' 'T1_NbC_X_W' 'T1_NbC_X_Y' 'T1_NbC_X_ZR' 'T1_NIAL_B2_X_AL'\n",
      " 'T1_NIAL_B2_X_CR' 'T1_NIAL_B2_X_FE' 'T1_NIAL_B2_X_NI' 'T1_NP_FCC'\n",
      " 'T1_NP_L12' 'T1_NP_M23C6' 'T1_NP_M2B_CB' 'T1_NP_M3B2_D5A' 'T1_NP_NbC'\n",
      " 'T1_NP_NIAL_B2' 'T1_VPV_FCC' 'T1_VPV_FECR_B2' 'T1_VPV_L12'\n",
      " 'T1_VPV_LAVES_C14' 'T1_VPV_M23C6' 'T1_VPV_M2B_CB' 'T1_VPV_M3B2_D5A'\n",
      " 'T1_VPV_NbC' 'T1_VPV_NIAL_B2' 'T1_VPV_SIGMA' 'T2' 'T2_DGM_FECR_B2'\n",
      " 'T2_DGM_L12' 'T2_DGM_NbC' 'T2_DGM_NIAL_B2' 'T2_FCC_ACR_AL'\n",
      " 'T2_FCC_ACR_CR' 'T2_FCC_ACR_CU' 'T2_FCC_ACR_FE' 'T2_FCC_ACR_MN'\n",
      " 'T2_FCC_ACR_MO' 'T2_FCC_ACR_NB' 'T2_FCC_ACR_NI' 'T2_FCC_ACR_SI'\n",
      " 'T2_FCC_ACR_TI' 'T2_FCC_ACR_V' 'T2_FCC_ACR_W' 'T2_FCC_ACR_Y'\n",
      " 'T2_FCC_ACR_ZR' 'T2_FCC_CX_AL' 'T2_FCC_CX_B' 'T2_FCC_CX_C' 'T2_FCC_CX_CR'\n",
      " 'T2_FCC_CX_CU' 'T2_FCC_CX_FE' 'T2_FCC_CX_MN' 'T2_FCC_CX_MO'\n",
      " 'T2_FCC_CX_NB' 'T2_FCC_CX_NI' 'T2_FCC_CX_SI' 'T2_FCC_CX_TI' 'T2_FCC_CX_V'\n",
      " 'T2_FCC_CX_W' 'T2_FCC_CX_Y' 'T2_FCC_CX_ZR' 'T2_FCC_X_AL' 'T2_FCC_X_B'\n",
      " 'T2_FCC_X_C' 'T2_FCC_X_CR' 'T2_FCC_X_CU' 'T2_FCC_X_FE' 'T2_FCC_X_MN'\n",
      " 'T2_FCC_X_MO' 'T2_FCC_X_NB' 'T2_FCC_X_NI' 'T2_FCC_X_SI' 'T2_FCC_X_TI'\n",
      " 'T2_FCC_X_V' 'T2_FCC_X_W' 'T2_FCC_X_Y' 'T2_FCC_X_ZR' 'T2_FECR_ACR_B2_AL'\n",
      " 'T2_FECR_ACR_B2_CR' 'T2_FECR_ACR_B2_FE' 'T2_FECR_ACR_B2_NI'\n",
      " 'T2_FECR_B2_X_AL' 'T2_FECR_B2_X_CR' 'T2_FECR_B2_X_FE' 'T2_FECR_B2_X_NI'\n",
      " 'T2_FECR_CX_AL' 'T2_FECR_CX_CR' 'T2_FECR_CX_FE' 'T2_FECR_CX_NI'\n",
      " 'T2_L12_ACR_AL' 'T2_L12_ACR_CR' 'T2_L12_ACR_CU' 'T2_L12_ACR_FE'\n",
      " 'T2_L12_ACR_MN' 'T2_L12_ACR_MO' 'T2_L12_ACR_NB' 'T2_L12_ACR_NI'\n",
      " 'T2_L12_ACR_SI' 'T2_L12_ACR_TI' 'T2_L12_ACR_V' 'T2_L12_ACR_W'\n",
      " 'T2_L12_ACR_Y' 'T2_L12_ACR_ZR' 'T2_L12_CX_AL' 'T2_L12_CX_B' 'T2_L12_CX_C'\n",
      " 'T2_L12_CX_CR' 'T2_L12_CX_CU' 'T2_L12_CX_FE' 'T2_L12_CX_MN'\n",
      " 'T2_L12_CX_MO' 'T2_L12_CX_NB' 'T2_L12_CX_NI' 'T2_L12_CX_SI'\n",
      " 'T2_L12_CX_TI' 'T2_L12_CX_V' 'T2_L12_CX_W' 'T2_L12_CX_Y' 'T2_L12_CX_ZR'\n",
      " 'T2_L12_X_AL' 'T2_L12_X_B' 'T2_L12_X_C' 'T2_L12_X_CR' 'T2_L12_X_CU'\n",
      " 'T2_L12_X_FE' 'T2_L12_X_MN' 'T2_L12_X_MO' 'T2_L12_X_NB' 'T2_L12_X_NI'\n",
      " 'T2_L12_X_SI' 'T2_L12_X_TI' 'T2_L12_X_V' 'T2_L12_X_W' 'T2_L12_X_Y'\n",
      " 'T2_L12_X_ZR' 'T2_LAVES_C14_ACR_AL' 'T2_LAVES_C14_ACR_CR'\n",
      " 'T2_LAVES_C14_ACR_CU' 'T2_LAVES_C14_ACR_FE' 'T2_LAVES_C14_ACR_MN'\n",
      " 'T2_LAVES_C14_ACR_MO' 'T2_LAVES_C14_ACR_NB' 'T2_LAVES_C14_ACR_NI'\n",
      " 'T2_LAVES_C14_ACR_SI' 'T2_LAVES_C14_ACR_TI' 'T2_LAVES_C14_ACR_V'\n",
      " 'T2_LAVES_C14_ACR_W' 'T2_LAVES_C14_ACR_Y' 'T2_LAVES_C14_ACR_ZR'\n",
      " 'T2_LAVES_C14_CX_AL' 'T2_LAVES_C14_CX_CR' 'T2_LAVES_C14_CX_CU'\n",
      " 'T2_LAVES_C14_CX_FE' 'T2_LAVES_C14_CX_MN' 'T2_LAVES_C14_CX_MO'\n",
      " 'T2_LAVES_C14_CX_NB' 'T2_LAVES_C14_CX_NI' 'T2_LAVES_C14_CX_SI'\n",
      " 'T2_LAVES_C14_CX_TI' 'T2_LAVES_C14_CX_V' 'T2_LAVES_C14_CX_W'\n",
      " 'T2_LAVES_C14_CX_Y' 'T2_LAVES_C14_CX_ZR' 'T2_LAVES_C14_X_AL'\n",
      " 'T2_LAVES_C14_X_CR' 'T2_LAVES_C14_X_CU' 'T2_LAVES_C14_X_FE'\n",
      " 'T2_LAVES_C14_X_MN' 'T2_LAVES_C14_X_MO' 'T2_LAVES_C14_X_NB'\n",
      " 'T2_LAVES_C14_X_NI' 'T2_LAVES_C14_X_SI' 'T2_LAVES_C14_X_TI'\n",
      " 'T2_LAVES_C14_X_V' 'T2_LAVES_C14_X_W' 'T2_LAVES_C14_X_Y'\n",
      " 'T2_LAVES_C14_X_ZR' 'T2_M23C6_CX_B' 'T2_M23C6_CX_C' 'T2_M23C6_CX_CR'\n",
      " 'T2_M23C6_CX_FE' 'T2_M23C6_CX_MN' 'T2_M23C6_CX_MO' 'T2_M23C6_CX_NI'\n",
      " 'T2_M23C6_CX_V' 'T2_M23C6_CX_W' 'T2_M23C6_X_B' 'T2_M23C6_X_C'\n",
      " 'T2_M23C6_X_CR' 'T2_M23C6_X_FE' 'T2_M23C6_X_MN' 'T2_M23C6_X_MO'\n",
      " 'T2_M23C6_X_NI' 'T2_M23C6_X_V' 'T2_M23C6_X_W' 'T2_M2B_CB_CX_B'\n",
      " 'T2_M2B_CB_CX_CR' 'T2_M2B_CB_CX_FE' 'T2_M2B_CB_CX_MN' 'T2_M2B_CB_CX_MO'\n",
      " 'T2_M2B_CB_CX_NI' 'T2_M2B_CB_X_B' 'T2_M2B_CB_X_CR' 'T2_M2B_CB_X_FE'\n",
      " 'T2_M2B_CB_X_MN' 'T2_M2B_CB_X_MO' 'T2_M2B_CB_X_NI' 'T2_M3B2_D5A_CX_B'\n",
      " 'T2_M3B2_D5A_CX_CR' 'T2_M3B2_D5A_CX_FE' 'T2_M3B2_D5A_CX_MO'\n",
      " 'T2_M3B2_D5A_CX_NI' 'T2_M3B2_D5A_CX_W' 'T2_M3B2_D5A_X_B'\n",
      " 'T2_M3B2_D5A_X_CR' 'T2_M3B2_D5A_X_FE' 'T2_M3B2_D5A_X_MO'\n",
      " 'T2_M3B2_D5A_X_NI' 'T2_M3B2_D5A_X_W' 'T2_NbC_ACR_AL' 'T2_NbC_ACR_CR'\n",
      " 'T2_NbC_ACR_CU' 'T2_NbC_ACR_FE' 'T2_NbC_ACR_MN' 'T2_NbC_ACR_MO'\n",
      " 'T2_NbC_ACR_NB' 'T2_NbC_ACR_NI' 'T2_NbC_ACR_SI' 'T2_NbC_ACR_TI'\n",
      " 'T2_NbC_ACR_V' 'T2_NbC_ACR_W' 'T2_NbC_ACR_Y' 'T2_NbC_ACR_ZR'\n",
      " 'T2_NbC_CX_AL' 'T2_NbC_CX_B' 'T2_NbC_CX_C' 'T2_NbC_CX_CR' 'T2_NbC_CX_CU'\n",
      " 'T2_NbC_CX_FE' 'T2_NbC_CX_MN' 'T2_NbC_CX_MO' 'T2_NbC_CX_NB'\n",
      " 'T2_NbC_CX_NI' 'T2_NbC_CX_SI' 'T2_NbC_CX_TI' 'T2_NbC_CX_V' 'T2_NbC_CX_W'\n",
      " 'T2_NbC_CX_Y' 'T2_NbC_CX_ZR' 'T2_NbC_X_AL' 'T2_NbC_X_B' 'T2_NbC_X_C'\n",
      " 'T2_NbC_X_CR' 'T2_NbC_X_CU' 'T2_NbC_X_FE' 'T2_NbC_X_MN' 'T2_NbC_X_MO'\n",
      " 'T2_NbC_X_NB' 'T2_NbC_X_NI' 'T2_NbC_X_SI' 'T2_NbC_X_TI' 'T2_NbC_X_V'\n",
      " 'T2_NbC_X_W' 'T2_NbC_X_Y' 'T2_NbC_X_ZR' 'T2_NIAL_ACR_B2_AL'\n",
      " 'T2_NIAL_ACR_B2_CR' 'T2_NIAL_ACR_B2_FE' 'T2_NIAL_ACR_B2_NI'\n",
      " 'T2_NIAL_B2_X_AL' 'T2_NIAL_B2_X_CR' 'T2_NIAL_B2_X_FE' 'T2_NIAL_B2_X_NI'\n",
      " 'T2_NIAL_CX_AL' 'T2_NIAL_CX_CR' 'T2_NIAL_CX_FE' 'T2_NIAL_CX_NI'\n",
      " 'T2_NP_FCC' 'T2_NP_FECR_B2' 'T2_NP_L12' 'T2_NP_LAVES_C14' 'T2_NP_M23C6'\n",
      " 'T2_NP_M2B_CB' 'T2_NP_M3B2_D5A' 'T2_NP_NbC' 'T2_NP_NIAL_B2' 'T2_NP_SIGMA'\n",
      " 'T2_SIGMA_CX_AL' 'T2_SIGMA_CX_CR' 'T2_SIGMA_CX_FE' 'T2_SIGMA_CX_MN'\n",
      " 'T2_SIGMA_CX_MO' 'T2_SIGMA_CX_NB' 'T2_SIGMA_CX_NI' 'T2_SIGMA_CX_SI'\n",
      " 'T2_SIGMA_CX_TI' 'T2_SIGMA_CX_V' 'T2_SIGMA_CX_W' 'T2_SIGMA_X_AL'\n",
      " 'T2_SIGMA_X_CR' 'T2_SIGMA_X_FE' 'T2_SIGMA_X_MN' 'T2_SIGMA_X_MO'\n",
      " 'T2_SIGMA_X_NB' 'T2_SIGMA_X_NI' 'T2_SIGMA_X_SI' 'T2_SIGMA_X_TI'\n",
      " 'T2_SIGMA_X_V' 'T2_SIGMA_X_W' 'T2_VPV_FCC' 'T2_VPV_FECR_B2' 'T2_VPV_L12'\n",
      " 'T2_VPV_LAVES_C14' 'T2_VPV_M23C6' 'T2_VPV_M2B_CB' 'T2_VPV_M3B2_D5A'\n",
      " 'T2_VPV_NbC' 'T2_VPV_NIAL_B2' 'T2_VPV_SIGMA' 'xAL' 'xB' 'xC' 'xCR' 'xCU'\n",
      " 'xFE' 'xMN' 'xMO' 'xNB' 'xNI' 'xSI' 'xTI' 'xV' 'xW' 'xY' 'xZR' 'Nb_C']\n",
      "Target Column Names: ['LMP']\n"
     ]
    }
   ],
   "source": [
    "# Setting input/target\n",
    "target_col = 498\n",
    "cols_to_remove = [0, 1, 499]\n",
    "random_state = 0\n",
    "\n",
    "# Loading the data\n",
    "data_df, x_train, y_train, header_x, header_y = data_load(file_to_load, cols_to_remove=cols_to_remove, target_col=target_col, random_state=random_state)\n",
    "\n",
    "print('Input Column Names:', header_x)\n",
    "print('Target Column Names:', header_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correlation analysis\n",
    "# corr_analysis(data_df, idx_to_key, cols_to_remove, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_x_ys(x_train, idx_of_stress):\n",
    "    # experimental code\n",
    "    x_train_enriched = []\n",
    "\n",
    "    y_1 = []\n",
    "    y_2 = []\n",
    "    \n",
    "    for i in range(0,len(x_train)):\n",
    "\n",
    "        x = x_train[i]\n",
    "        y = y_train[i][0]\n",
    "        Stress = x[idx_of_stress]\n",
    "\n",
    "        new_x = list(x)\n",
    "        if(Stress) ==70:\n",
    "            new_x.append(24563.25)\n",
    "            new_x.append(24126)\n",
    "        elif(Stress) ==100:\n",
    "            new_x.append(23592)\n",
    "            new_x.append(23174)\n",
    "        elif(Stress) ==130:\n",
    "            new_x.append(22812.5)\n",
    "            new_x.append(22553)\n",
    "        elif(Stress) ==170:\n",
    "            new_x.append(22198)\n",
    "            new_x.append(22050.5)\n",
    "        elif(Stress) ==200:\n",
    "            new_x.append(21612.5)\n",
    "            new_x.append(21276)\n",
    "        elif(Stress) ==250:\n",
    "            new_x.append(20899.25)\n",
    "            new_x.append(20562)\n",
    "        elif(Stress) ==300:\n",
    "            new_x.append(20317.75)\n",
    "            new_x.append(19825.5)\n",
    "        else:\n",
    "            print(\"Error!\")\n",
    "\n",
    "        if(new_x[-1]<y):\n",
    "            y_1.append([1])\n",
    "        else:\n",
    "            y_1.append([0])\n",
    "\n",
    "        if(new_x[-2]<y):\n",
    "            y_2.append([1])\n",
    "        else:\n",
    "            y_2.append([0])\n",
    "\n",
    "        x_train_enriched.append(new_x)\n",
    "\n",
    "    x_train_enriched = np.array(x_train_enriched)\n",
    "    x_train = x_train_enriched\n",
    "    y_1 = np.array(y_1)\n",
    "    y_2 = np.array(y_2)\n",
    "    return x_train, y_1, y_2\n",
    "\n",
    "x_train, y_1, y_2 = get_new_x_ys(x_train, idx_of_stress=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 66)                32934     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 253)               16951     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 110)               27940     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 244)               27084     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 245       \n",
      "=================================================================\n",
      "Total params: 105,154\n",
      "Trainable params: 105,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training initiated ..\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCn4RkQij4BcRiTAKfhGRCPP/SQMRt+BHhZAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAkjhLiISQAp3EZEA+v/pFDZI/n0SQwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "layer = 4\n",
    "params = [66, 253, 110, 244]\n",
    "dropout = 0\n",
    "l_2 = 0.0067\n",
    "lr=0.000021\n",
    "epochs = 1000\n",
    "batch_size = 2\n",
    "num_of_folds = 5\n",
    "j = 0\n",
    "\n",
    "# Splitting the data for k-fold cross validation\n",
    "x_trains, y_trains, x_tests, y_tests = split_data(x_train, y_2, num_of_folds=num_of_folds)\n",
    "\n",
    "# defining a model\n",
    "model = model_define_classifier(params = params, layer_n = layer, input_size = x_trains[j].shape[1], dropout=dropout, l_2=l_2)\n",
    "model.summary()\n",
    "\n",
    "# choose your scaler\n",
    "scale = StandardScaler()\n",
    "x_train_ = scale.fit_transform(x_trains[j])\n",
    "\n",
    "# This is the change\n",
    "x_test_ = scale.transform(x_tests[j])\n",
    "\n",
    "# evaluating a model\n",
    "print('Training initiated ..')\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "score, history = evaluate_model_classifier(model, epochs=epochs, batch_size=batch_size, x_train = x_train_, y_train = y_trains[0], x_test = x_test_, y_test = y_tests[0], verbose = 0, optimizer=optimizer)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()\n",
    "\n",
    "print('Model Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 66)                32934     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 66)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 253)               16951     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 253)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 110)               27940     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 244)               27084     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 245       \n",
      "=================================================================\n",
      "Total params: 105,154\n",
      "Trainable params: 105,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training initiated ..\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXkQkyynoRUSy3P8HGrPAvlLJTngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test mean_absolute_percentage_error: 4.978157303550026\n"
     ]
    }
   ],
   "source": [
    "layer = 4\n",
    "params = [11, 1, 80, 95]\n",
    "dropout = 0.0119\n",
    "l_2 = 0.0481\n",
    "lr=0.000262\n",
    "epochs = 1000\n",
    "batch_size = 2\n",
    "num_of_folds = 5\n",
    "j = 0\n",
    "\n",
    "# Splitting the data for k-fold cross validation\n",
    "x_trains, y_trains, x_tests, y_tests = split_data(x_train, y_train, num_of_folds=num_of_folds)\n",
    "\n",
    "# defining a model\n",
    "model = model_define(params = params, layer_n = layer, input_size = x_trains[j].shape[1], dropout=dropout, l_2=l_2)\n",
    "model.summary()\n",
    "\n",
    "# choose your scaler\n",
    "scale = StandardScaler()\n",
    "x_train_ = scale.fit_transform(x_trains[j])\n",
    "\n",
    "# This is the change\n",
    "x_test_ = scale.transform(x_tests[j])\n",
    "\n",
    "# evaluating a model\n",
    "print('Training initiated ..')\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "score, history = evaluate_model(model, epochs=epochs, batch_size=batch_size, x_train = x_train_, y_train = y_trains[0], x_test = x_test_, y_test = y_tests[0], verbose = 0, optimizer=optimizer)\n",
    "plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "plt.show()\n",
    "\n",
    "print('Model Test mean_absolute_percentage_error:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8Zv/B3aeBNWOnAsGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the prediction\n",
    "show_comparison_chart(model, x_test_, y_tests[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ieterative training for hyperparameter tuning for regression\n",
    "\n",
    "'''\n",
    "layer = 4\n",
    "params = [3, 207, 191, 119]\n",
    "dropout = 0.0119\n",
    "l_2 = 0.0481\n",
    "lr=0.000262\n",
    "epochs = 1000\n",
    "batch_size = 2\n",
    "random_state = 0\n",
    "\n",
    "# score = 1.057-1.501@epoch=1000\n",
    "\n",
    "'''\n",
    "\n",
    "layer = None\n",
    "params = None\n",
    "dropout = 0.0119\n",
    "l_2 = 0.0481\n",
    "lr = 0.000262\n",
    "epochs = 1000\n",
    "batch_size = 2\n",
    "num_of_folds = 5\n",
    "tries = 1000\n",
    "neuron_max = 256\n",
    "batch_size_max = 5\n",
    "layer_min = 4\n",
    "layer_max = 4\n",
    "dropout_max=0.02\n",
    "\n",
    "# data_df, x_train, y_train, header_x, header_y = data_load(file_to_load, cols_to_remove=cols_to_remove, target_col=target_col, random_state=random_state)\n",
    "# x_trains, y_trains, x_tests, y_tests = split_data(x_train, y_1, num_of_folds=num_of_folds)\n",
    "# hp_tuning(tries = tries, lr = lr, x_trains = x_trains, y_trains = y_trains, x_tests = x_tests, y_tests = y_tests, layer = layer, params=params, epochs=epochs, batch_size=batch_size, dropout=dropout, l_2 = l_2, neuron_max=neuron_max, batch_size_max=batch_size_max, layer_min = layer_min, layer_max=layer_max, dropout_max=dropout_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- STARTED, don't panic and wait --\n",
      "Iteration 0 (fold:1):\t[66, 253, 110, 244]\t200\t0.0006782944732439745\t2\t 0.02007\t   0.758\t  94.209\tlr=0.000155\n",
      "Iteration 0 (fold:2):\t[66, 253, 110, 244]\t200\t0.0006782944732439745\t2\t 0.02007\t   0.818\t 100.384\tlr=0.000155\n",
      "Iteration 0 (fold:3):\t[66, 253, 110, 244]\t200\t0.0006782944732439745\t2\t 0.02007\t   0.939\t 104.029\tlr=0.000155\n",
      "Iteration 0 (fold:4):\t[66, 253, 110, 244]\t200\t0.0006782944732439745\t2\t 0.02007\t   0.853\t  99.020\tlr=0.000155\n",
      "average score =  0.8420231729055259\n",
      "best score =    0.842 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0007, l_2=  0.0201, batch_size=2, lr=0.000155]\n",
      "Iteration 1 (fold:1):\t[66, 253, 110, 244]\t200\t0.017950287698503764\t2\t 0.00198\t   0.788\t  95.508\tlr=0.000252\n",
      "Iteration 1 (fold:2):\t[66, 253, 110, 244]\t200\t0.017950287698503764\t2\t 0.00198\t   0.848\t  97.479\tlr=0.000252\n",
      "Iteration 1 (fold:3):\t[66, 253, 110, 244]\t200\t0.017950287698503764\t2\t 0.00198\t   0.939\t  91.584\tlr=0.000252\n",
      "Iteration 1 (fold:4):\t[66, 253, 110, 244]\t200\t0.017950287698503764\t2\t 0.00198\t   0.824\t  75.722\tlr=0.000252\n",
      "average score =  0.8498217468805704\n",
      "best score =    0.850 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0180, l_2=  0.0020, batch_size=2, lr=0.000252]\n",
      "Iteration 2 (fold:1):\t[66, 253, 110, 244]\t200\t0.004239980201033682\t2\t 0.00351\t   0.788\t  94.538\tlr=0.000016\n",
      "Iteration 2 (fold:2):\t[66, 253, 110, 244]\t200\t0.004239980201033682\t2\t 0.00351\t   0.818\t 102.085\tlr=0.000016\n",
      "Iteration 2 (fold:3):\t[66, 253, 110, 244]\t200\t0.004239980201033682\t2\t 0.00351\t   0.909\t 106.202\tlr=0.000016\n",
      "Iteration 2 (fold:4):\t[66, 253, 110, 244]\t200\t0.004239980201033682\t2\t 0.00351\t   0.735\t 105.145\tlr=0.000016\n",
      "average score =  0.8126114081996435\n",
      "best score =    0.850 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0180, l_2=  0.0020, batch_size=2, lr=0.000252]\n",
      "Iteration 3 (fold:1):\t[66, 253, 110, 244]\t200\t0.014899618456742637\t2\t 0.00318\t   0.788\t 110.837\tlr=0.000069\n",
      "Iteration 3 (fold:2):\t[66, 253, 110, 244]\t200\t0.014899618456742637\t2\t 0.00318\t   0.848\t 113.019\tlr=0.000069\n",
      "Iteration 3 (fold:3):\t[66, 253, 110, 244]\t200\t0.014899618456742637\t2\t 0.00318\t   0.939\t 115.630\tlr=0.000069\n",
      "Iteration 3 (fold:4):\t[66, 253, 110, 244]\t200\t0.014899618456742637\t2\t 0.00318\t   0.824\t 108.012\tlr=0.000069\n",
      "average score =  0.8498217468805704\n",
      "best score =    0.850 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0180, l_2=  0.0020, batch_size=2, lr=0.000252]\n",
      "Iteration 4 (fold:1):\t[66, 253, 110, 244]\t200\t0.0038980526754272015\t2\t 0.03909\t   0.848\t  92.568\tlr=0.000329\n",
      "Iteration 4 (fold:2):\t[66, 253, 110, 244]\t200\t0.0038980526754272015\t2\t 0.03909\t   0.788\t 105.159\tlr=0.000329\n",
      "Iteration 4 (fold:3):\t[66, 253, 110, 244]\t200\t0.0038980526754272015\t2\t 0.03909\t   0.909\t 127.808\tlr=0.000329\n",
      "Iteration 4 (fold:4):\t[66, 253, 110, 244]\t200\t0.0038980526754272015\t2\t 0.03909\t   0.824\t 120.922\tlr=0.000329\n",
      "average score =  0.8422459893048129\n",
      "best score =    0.850 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0180, l_2=  0.0020, batch_size=2, lr=0.000252]\n",
      "Iteration 5 (fold:1):\t[66, 253, 110, 244]\t200\t0.005081144897860479\t2\t 0.04902\t   0.818\t 112.186\tlr=0.000020\n",
      "Iteration 5 (fold:2):\t[66, 253, 110, 244]\t200\t0.005081144897860479\t2\t 0.04902\t   0.788\t 119.062\tlr=0.000020\n",
      "Iteration 5 (fold:3):\t[66, 253, 110, 244]\t200\t0.005081144897860479\t2\t 0.04902\t   0.909\t 140.122\tlr=0.000020\n",
      "Iteration 5 (fold:4):\t[66, 253, 110, 244]\t200\t0.005081144897860479\t2\t 0.04902\t   0.735\t 111.583\tlr=0.000020\n",
      "average score =  0.8126114081996435\n",
      "best score =    0.850 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0180, l_2=  0.0020, batch_size=2, lr=0.000252]\n",
      "Iteration 6 (fold:1):\t[66, 253, 110, 244]\t200\t0.016325624799795827\t2\t 0.02257\t   0.788\t 116.811\tlr=0.000519\n",
      "Iteration 6 (fold:2):\t[66, 253, 110, 244]\t200\t0.016325624799795827\t2\t 0.02257\t   0.818\t 120.365\tlr=0.000519\n",
      "Iteration 6 (fold:3):\t[66, 253, 110, 244]\t200\t0.016325624799795827\t2\t 0.02257\t   0.939\t 128.403\tlr=0.000519\n",
      "Iteration 6 (fold:4):\t[66, 253, 110, 244]\t200\t0.016325624799795827\t2\t 0.02257\t   0.735\t 120.519\tlr=0.000519\n",
      "average score =  0.8201871657754011\n",
      "best score =    0.850 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0180, l_2=  0.0020, batch_size=2, lr=0.000252]\n",
      "Iteration 7 (fold:1):\t[66, 253, 110, 244]\t200\t0.018015904967886315\t2\t 0.00340\t   0.848\t 133.198\tlr=0.000735\n",
      "Iteration 7 (fold:2):\t[66, 253, 110, 244]\t200\t0.018015904967886315\t2\t 0.00340\t   0.818\t 126.672\tlr=0.000735\n",
      "Iteration 7 (fold:3):\t[66, 253, 110, 244]\t200\t0.018015904967886315\t2\t 0.00340\t   0.939\t 133.732\tlr=0.000735\n",
      "Iteration 7 (fold:4):\t[66, 253, 110, 244]\t200\t0.018015904967886315\t2\t 0.00340\t   0.824\t 106.742\tlr=0.000735\n",
      "average score =  0.857397504456328\n",
      "best score =    0.857 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0180, l_2=  0.0034, batch_size=2, lr=0.000735]\n",
      "Iteration 8 (fold:1):\t[66, 253, 110, 244]\t200\t0.005566299384722416\t2\t 0.00666\t   0.788\t 128.941\tlr=0.000908\n",
      "Iteration 8 (fold:2):\t[66, 253, 110, 244]\t200\t0.005566299384722416\t2\t 0.00666\t   0.848\t 128.947\tlr=0.000908\n",
      "Iteration 8 (fold:3):\t[66, 253, 110, 244]\t200\t0.005566299384722416\t2\t 0.00666\t   0.939\t 118.605\tlr=0.000908\n",
      "Iteration 8 (fold:4):\t[66, 253, 110, 244]\t200\t0.005566299384722416\t2\t 0.00666\t   0.794\t 125.075\tlr=0.000908\n",
      "average score =  0.8424688057040998\n",
      "best score =    0.857 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0180, l_2=  0.0034, batch_size=2, lr=0.000735]\n",
      "Iteration 9 (fold:1):\t[66, 253, 110, 244]\t200\t0.0003658510102774559\t2\t 0.00561\t   0.788\t 128.573\tlr=0.000157\n",
      "Iteration 9 (fold:2):\t[66, 253, 110, 244]\t200\t0.0003658510102774559\t2\t 0.00561\t   0.879\t 164.180\tlr=0.000157\n",
      "Iteration 9 (fold:3):\t[66, 253, 110, 244]\t200\t0.0003658510102774559\t2\t 0.00561\t   0.939\t 114.894\tlr=0.000157\n"
     ]
    }
   ],
   "source": [
    "# Ieterative training for hyperparameter tuning for binary classification\n",
    "\n",
    "'''\n",
    "layer = 4\n",
    "params = [3, 207, 191, 119]\n",
    "dropout = 0.0119\n",
    "l_2 = 0.0481\n",
    "lr=0.000262\n",
    "epochs = 1000\n",
    "batch_size = 2\n",
    "random_state = 0\n",
    "\n",
    "# score = 1.057-1.501@epoch=1000\n",
    "\n",
    "'''\n",
    "\n",
    "layer = 4\n",
    "params = [66, 253, 110, 244]\n",
    "dropout = True\n",
    "l_2 = None\n",
    "lr = None\n",
    "epochs = 200\n",
    "batch_size = 2\n",
    "num_of_folds = 5\n",
    "tries = 1000\n",
    "neuron_max = 256\n",
    "batch_size_max = 5\n",
    "layer_min = 2\n",
    "layer_max = 4\n",
    "dropout_max=0.02\n",
    "\n",
    "data_df, x_train, y_train, header_x, header_y = data_load(file_to_load, cols_to_remove=cols_to_remove, target_col=target_col, random_state=random_state)\n",
    "x_train, y_1, y_2 = get_new_x_ys(x_train, idx_of_stress=12)\n",
    "x_trains, y_trains, x_tests, y_tests = split_data(x_train, y_2, num_of_folds=num_of_folds)\n",
    "\n",
    "hp_tuning_classification(tries = tries, lr = lr, x_trains = x_trains, y_trains = y_trains, x_tests = x_tests, y_tests = y_tests, layer = layer, params=params, epochs=epochs, batch_size=batch_size, dropout=dropout, l_2 = l_2, neuron_max=neuron_max, batch_size_max=batch_size_max, layer_min = layer_min, layer_max=layer_max, dropout_max=dropout_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (y_1) best score =    0.820 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0139, l_2=  0.0206, batch_size=2, lr=0.000121]\n",
    "# (y_2) best score =    0.850 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0180, l_2=  0.0020, batch_size=2, lr=0.000252]\n",
    "# (y_2) best score =    0.857 [layer=4, params=[[66, 253, 110, 244]], epochs=200, dropout=  0.0180, l_2=  0.0034, batch_size=2, lr=0.000735]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
