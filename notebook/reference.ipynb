{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import ascends as asc\n",
    "import keras\n",
    "import ast\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Regression API reference\n",
    "\n",
    "# * NOTE: Ascends-toolkit was developed to be used via command-line interface or web-based interface; however, if needed,\n",
    "# users may use ascends-toolkit's API. The following shows an example of performing a classification task using \n",
    "# the core ascends-toolkit APIs. \n",
    "\n",
    "csv_file = '../data/iris.csv'\n",
    "cols_to_remove = []\n",
    "target_col = 'Name'\n",
    "input_col = None\n",
    "\n",
    "# Classifier will need a mapping between categorical values to numerical values\n",
    "mapping = {'Name': {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}}\n",
    "\n",
    "# Load data from csv file\n",
    "# A standard csv file can be loaded and shuffled as follows\n",
    "\n",
    "data_df, x_train, y_train, header_x, header_y = asc.data_load_shuffle(csv_file, input_col, cols_to_remove, target_col, map_all = mapping, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Name\n",
       "0          5.1         3.5          1.4         0.2     0\n",
       "1          4.9         3.0          1.4         0.2     0\n",
       "2          4.7         3.2          1.3         0.2     0\n",
       "3          4.6         3.1          1.5         0.2     0\n",
       "4          5.0         3.6          1.4         0.2     0\n",
       "5          5.4         3.9          1.7         0.4     0\n",
       "6          4.6         3.4          1.4         0.3     0\n",
       "7          5.0         3.4          1.5         0.2     0\n",
       "8          4.4         2.9          1.4         0.2     0\n",
       "9          4.9         3.1          1.5         0.1     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if data is loaded\n",
    "data_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if asc.data_load_shuffle() worked correctly\n",
    "\n",
    "assert data_df['SepalLength'].values[0] == 5.1\n",
    "assert data_df['SepalWidth'].values[3] == 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a default model parameters\n",
    "model_parameters = asc.default_model_parameters_classifier() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'RF'\n",
    "scaler_option = 'StandardScaler' # scaler option can be 'False','StandardScaler','Normalizer','MinMaxScaler','RobustScaler'\n",
    "num_of_folds = 5\n",
    "model = asc.define_model_classifier(model_type, model_parameters, x_header_size = x_train.shape[1], random_state = 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        50\n",
      "         1.0       0.94      0.94      0.94        50\n",
      "         2.0       0.94      0.94      0.94        50\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       150\n",
      "   macro avg       0.96      0.96      0.96       150\n",
      "weighted avg       0.96      0.96      0.96       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn's classification report can be used to understand the accuracy of the trained model\n",
    "predictions, actual_values = asc.train_and_predict(model, x_train, y_train, scaler_option=scaler_option, num_of_folds=num_of_folds)\n",
    "accuracy = asc.evaluate_classifier(predictions, actual_values)\n",
    "print(\"\")\n",
    "print(\"* Classification Report\")\n",
    "print(classification_report(actual_values, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if we achieved the correct accuracy\n",
    "assert accuracy == 0.96\n",
    "assert list(predictions) == [2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0,\n",
    " 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 0, 1, 2, 2,\n",
    " 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1,\n",
    " 0, 0, 1, 0, 2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2,\n",
    " 0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2,\n",
    " 0, 2, 0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 2, 2, 0, 1, 2, 2, 0, 1, 1, 2, 1, 0,\n",
    " 0, 0, 2, 1, 2, 0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training initiated ..\n",
      "* Training done.\n",
      "* Trained model saved to file: model.pkl\n"
     ]
    }
   ],
   "source": [
    "asc.train_and_save_classifier(model, \"model.pkl\", model_type\n",
    "                            , input_cols=header_x, target_col=header_y\n",
    "                            , x_train=x_train, y_train=y_train, scaler_option=scaler_option, path_to_save = '.', accuracy=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled x_to_predict =  [[-1.62768837 -1.51337555 -1.45500383  3.94594202]]\n",
      "* Your model thinks that it's a  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# You can load the saved model by using pickle package\n",
    "model_dict = pickle.load(open('model.pkl', 'rb'))\n",
    "\n",
    "# Let's assume that we have a input as follows\n",
    "x_to_predict = [[4.5, 2.4, 1.2, 4.2]]\n",
    "\n",
    "# You can scale the data using the loaded scaler\n",
    "scaler = model_dict['fitted_scaler_x']\n",
    "x_to_predict = scaler.transform(x_to_predict)\n",
    "print(\"Scaled x_to_predict = \", x_to_predict)\n",
    "\n",
    "# Making prediction can be done as follows\n",
    "predicted_y = model.predict(x_to_predict)\n",
    "\n",
    "# Original prediction value will not be a class name, so you need to find out the class name by doing:\n",
    "for key in mapping['Name'].keys():\n",
    "    if mapping['Name'][key]==predicted_y[0]:\n",
    "        print(\"* Your model thinks that it's a \", key)\n",
    "        \n",
    "        # test if our prediction is correctly done\n",
    "        assert key=='Iris-setosa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Regression API reference\n",
    "\n",
    "# * NOTE: Ascends-toolkit was developed to be used via command-line interface or web-based interface; however, if needed,\n",
    "# users may use ascends-toolkit's API. The following shows an example of performing a regression task using \n",
    "# the core ascends-toolkit APIs\n",
    "\n",
    "csv_file = '../data/BostonHousing.csv'\n",
    "cols_to_remove = []\n",
    "target_col = 'medv'\n",
    "\n",
    "# Load data from csv file\n",
    "# A standard csv file can be loaded and shuffled as follows\n",
    "\n",
    "data_df, x_train, y_train, header_x, header_y = asc.data_load_shuffle(csv_file, None, cols_to_remove, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* correlation_analysis_all\n",
      "Top-k features for each criteria\n",
      "{'PCC': ['rm', 'zn', 'b', 'dis', 'chas', 'age', 'rad', 'crim', 'nox', 'tax'], 'PCC_SQRT': ['lstat', 'rm', 'ptratio', 'indus', 'tax', 'nox', 'crim', 'rad', 'age', 'zn'], 'MIC': ['lstat', 'rm', 'nox', 'age', 'indus', 'ptratio', 'crim', 'tax', 'dis', 'zn'], 'MAS': ['chas', 'b', 'age', 'zn', 'rad', 'dis', 'nox', 'ptratio', 'crim', 'tax'], 'MEV': ['lstat', 'rm', 'nox', 'age', 'indus', 'ptratio', 'crim', 'tax', 'dis', 'zn'], 'MCN': ['zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio'], 'MCN_general': ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax'], 'GMIC': ['lstat', 'rm', 'nox', 'age', 'indus', 'ptratio', 'crim', 'tax', 'dis', 'rad'], 'TIC': ['lstat', 'rm', 'nox', 'indus', 'ptratio', 'age', 'crim', 'tax', 'dis', 'rad']}\n",
      "\n",
      "Full Correlation Analysis report\n",
      "              MIC       MAS       MEV       MCN  MCN_general      GMIC  \\\n",
      "age      0.420689  0.099268  0.420689  5.321928          2.0  0.368688   \n",
      "b        0.272469  0.112505  0.272469  5.321928          2.0  0.207560   \n",
      "chas     0.133026  0.113481  0.133026  5.321928          2.0  0.079504   \n",
      "crim     0.358757  0.044427  0.358757  5.000000          2.0  0.326953   \n",
      "dis      0.315033  0.055968  0.315033  5.321928          2.0  0.282479   \n",
      "indus    0.414140  0.039397  0.414140  5.321928          2.0  0.350791   \n",
      "lstat    0.615427  0.034828  0.615427  5.321928          2.0  0.563114   \n",
      "nox      0.442723  0.047576  0.442723  5.321928          2.0  0.390978   \n",
      "ptratio  0.371581  0.045671  0.371581  5.321928          2.0  0.335871   \n",
      "rad      0.278780  0.060237  0.278780  5.321928          2.0  0.238301   \n",
      "rm       0.450967  0.038707  0.450967  5.321928          2.0  0.429243   \n",
      "tax      0.324490  0.041496  0.324490  5.321928          2.0  0.287834   \n",
      "zn       0.289734  0.098851  0.289734  5.321928          2.0  0.236065   \n",
      "\n",
      "               TIC  PCC_SQRT       PCC  \n",
      "age      21.160602  0.376955 -0.376955  \n",
      "b        11.615744  0.333461  0.333461  \n",
      "chas      4.074539  0.175260  0.175260  \n",
      "crim     21.033617  0.388305 -0.388305  \n",
      "dis      18.077608  0.249929  0.249929  \n",
      "indus    23.199544  0.483725 -0.483725  \n",
      "lstat    38.803088  0.737663 -0.737663  \n",
      "nox      25.119383  0.427321 -0.427321  \n",
      "ptratio  21.688436  0.507787 -0.507787  \n",
      "rad      14.967824  0.381626 -0.381626  \n",
      "rm       28.144318  0.695360  0.695360  \n",
      "tax      19.708624  0.468536 -0.468536  \n",
      "zn       12.802512  0.360445  0.360445  \n"
     ]
    }
   ],
   "source": [
    "# Performing correlation analysis\n",
    "# Correlation analysis can be performed as follows\n",
    "# fs_dict will only contain the top-k features for each criteria (e.g., PCC)\n",
    "# final_report will contain the full evaluation scores for each feature\n",
    "\n",
    "k = 10\n",
    "fs_dict, final_report = asc.correlation_analysis_all(data_df, target_col, top_k = k, file_to_save = None, save_chart = None)\n",
    "\n",
    "print(\"Top-k features for each criteria\")\n",
    "print(fs_dict)\n",
    "print(\"\")\n",
    "print(\"Full Correlation Analysis report\")\n",
    "print(final_report)\n",
    "\n",
    "# To use top-k (k=10) features based on PCC (Pearson's correlation coefficient)\n",
    "\n",
    "input_col = fs_dict['PCC']\n",
    "\n",
    "# We need to load the file again\n",
    "data_df, x_train, y_train, header_x, header_y = asc.data_load_shuffle(csv_file, input_col, cols_to_remove, target_col)\n",
    "\n",
    "# testing correlation analysis report test\n",
    "\n",
    "assert (final_report['MIC'][0]==0.42068867557196804)\n",
    "assert (final_report['MEV'][0] == 0.42068867557196804)\n",
    "assert (final_report['MCN'][0]==5.321928094887363)\n",
    "assert (final_report['MCN_general'][0]==2.0)\n",
    "assert (final_report['GMIC'][0]==0.3686876195636089)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  2.8159565143151717 , R2 =  0.7011306697815759\n"
     ]
    }
   ],
   "source": [
    "# Generating a default model parameters\n",
    "model_parameters = asc.default_model_parameters() \n",
    "\n",
    "# Model Training\n",
    "model_type = 'RF' # model type can be 'LR','RF','NN','KR','BR','SVM'\n",
    "scaler_option = 'StandardScaler' # scaler option can be 'False','StandardScaler','Normalizer','MinMaxScaler','RobustScaler'\n",
    "num_of_folds = 5\n",
    "model = asc.define_model_regression(model_type, model_parameters, x_header_size = x_train.shape[1], random_state=0)\n",
    "predictions, actual_values = asc.train_and_predict(model, x_train, y_train, scaler_option=scaler_option, num_of_folds=num_of_folds)\n",
    "MAE, R2 = asc.evaluate(predictions, actual_values)\n",
    "\n",
    "# Printing the performance of regression task\n",
    "print(\"MAE = \", MAE,\", R2 = \", R2)\n",
    "\n",
    "# test if we achieved the correct result\n",
    "assert MAE == 2.8159565143151717\n",
    "assert R2 == 0.7011306697815759\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   42.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:  8.5min finished\n",
      "/anaconda3/envs/ascends/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# tuning hyper parameters\n",
    "tuned_parameters = asc.hyperparameter_tuning(model_type, x_train, y_train\n",
    "                                             , num_of_folds, scaler_option\n",
    "                                           , n_iter=1000, random_state=0, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  2.6527868127203824 , R2 =  0.7799033856883656\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "model_type = 'RF' # model type can be 'LR','RF','NN','KR','BR','SVM'\n",
    "scaler_option = 'StandardScaler' # scaler option can be 'False','StandardScaler','Normalizer','MinMaxScaler','RobustScaler'\n",
    "num_of_folds = 5\n",
    "model = asc.define_model_regression(model_type, tuned_parameters, x_header_size = x_train.shape[1], random_state=0)\n",
    "predictions, actual_values = asc.train_and_predict(model, x_train, y_train, scaler_option=scaler_option, num_of_folds=num_of_folds)\n",
    "MAE, R2 = asc.evaluate(predictions, actual_values)\n",
    "\n",
    "# Printing the performance of regression task\n",
    "print(\"MAE = \", MAE,\", R2 = \", R2)\n",
    "\n",
    "# test if we achieved the correct result\n",
    "assert MAE == 2.6527868127203824\n",
    "assert R2 == 0.7799033856883656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction-actual result in a csv file\n",
    "asc.save_test_data(predictions, actual_values, \"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Training initiated ..\n",
      "* Training done.\n",
      "* Trained model saved to file: trained_model\n"
     ]
    }
   ],
   "source": [
    "# saving the trained model in a file\n",
    "asc.train_and_save(model, \"trained_model\", model_type\n",
    "                        , input_cols=header_x, target_col=header_y\n",
    "                        , x_train=x_train, y_train=y_train, scaler_option=scaler_option, path_to_save = '.', MAE=MAE, R2=R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model file loading and making a prediction can be done in the same way as the classification example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
