{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ascends as asc\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding some more data for this particular example\n",
    "\n",
    "def add_reference_alloy_data(x_train, header_x, stress_key = 'Stress'):\n",
    "    \n",
    "    for i in range(0, len(header_x)):\n",
    "        if(header_x[i]==stress_key):\n",
    "            idx_of_stress = i\n",
    "    \n",
    "    # experimental code\n",
    "    x_train_update = []\n",
    "\n",
    "    y_1 = []\n",
    "    y_2 = []\n",
    "    \n",
    "    for i in range(0,len(x_train)):\n",
    "\n",
    "        x = x_train[i]\n",
    "        y = y_train[i][0]\n",
    "        Stress = x[idx_of_stress]\n",
    "\n",
    "        # data came fromTP347HFG-NF709, TP347HFG reference alloys\n",
    "        x_update = list(x)\n",
    "        if(Stress) ==70:\n",
    "            x_update+=[24563.25,24126]\n",
    "        elif(Stress) ==100:\n",
    "            x_update+=[23592,23174]\n",
    "        elif(Stress) ==130:\n",
    "            x_update+=[22812.5,22553]\n",
    "        elif(Stress) ==170:\n",
    "            x_update+=[22198,22050.5]\n",
    "        elif(Stress) ==200:\n",
    "            x_update+=[21612.5,21276]\n",
    "        elif(Stress) ==250:\n",
    "            x_update+=[20899.25,20562]\n",
    "        elif(Stress) ==300:\n",
    "            x_update+=[20317.75,19825.5]\n",
    "\n",
    "        if(x_update[-1]<y):\n",
    "            y_1.append([1])\n",
    "        else:\n",
    "            y_1.append([0])\n",
    "\n",
    "        if(x_update[-2]<y):\n",
    "            y_2.append([1])\n",
    "        else:\n",
    "            y_2.append([0])\n",
    "\n",
    "        x_train_update.append(x_update)\n",
    "\n",
    "    x_train_update = np.array(x_train_update)\n",
    "    x_train = x_train_update\n",
    "    y_1 = np.array(y_1)\n",
    "    y_2 = np.array(y_2)\n",
    "    \n",
    "    header_x = np.append(header_x, ['TP347HFG-NF709', 'TP347HFG'])\n",
    "\n",
    "    return x_train, header_x, y_1, y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a config file from\n",
    "config_file = 'config/creep_more_features.properties'\n",
    "\n",
    "# Now all config parameters are set \n",
    "config, csv_file, cols_to_remove, target_col, scaler_option, path_to_mine_jar, \\\n",
    "output_dir, num_of_features, num_of_folds, num_of_sets, model_parameters = asc.load_cfg(config_file)\n",
    "\n",
    "print(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from csv file\n",
    "data_df, x_train, y_train, header_x, header_y = asc.data_load_shuffle(csv_file, None, cols_to_remove, target_col)\n",
    "\n",
    "# enrich data (optional), in this example, we added two more columns by using a custom function\n",
    "x_train, header_x, y_1, y_2 = add_reference_alloy_data(x_train, header_x, stress_key='Stress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# performing correlation analysis\n",
    "correlation_rank = asc.corr_analysis(data_df, target_col, csv_file, path_to_mine_jar, output_dir, show_charts=False, top_k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model_type = 'RF' # model type can be 'LR','RF','NN','KR','BR','SVM'\n",
    "model = asc.define_model_regression(model_type, num_of_features, model_parameters, x_header_size = x_train.shape[1])\n",
    "\n",
    "# Train and Predict\n",
    "predictions, actual_values = asc.train_and_predict(model, x_train, y_train, scaler_option, num_of_folds=num_of_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluation (k-fold cross validation)\n",
    "RMSE, R2 = asc.evaluate(predictions, actual_values)\n",
    "asc.show_comparison_chart(predictions, actual_values)\n",
    "print(\"* not tuned (%s)\\t RMSE = %8.3f, R2 = %8.3f\"%(model_type, RMSE, R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning hyper parameters\n",
    "tuned_parameters = asc.hyperparameter_tuning(model_type, x_train, y_train\n",
    "                                             , num_of_folds, scaler_option\n",
    "                                           , n_iter=2000, random_state=0, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model training (with tuned parameters)\n",
    "model = asc.define_model_regression(model_type, num_of_features, model_parameters = tuned_parameters, x_header_size = x_train.shape[1])\n",
    "\n",
    "# Train and Predict\n",
    "predictions, actual_values = asc.train_and_predict(model, x_train, y_train, scaler_option, num_of_folds=num_of_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation (k-fold cross validation) after hyperparameter tuning\n",
    "RMSE, R2 = asc.evaluate(predictions, actual_values)\n",
    "asc.show_comparison_chart(predictions, actual_values)\n",
    "print(\"* tuned (%s)\\t RMSE = %8.3f, R2 = %8.3f\"%(model_type, RMSE, R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and save\n",
    "model = asc.define_model_regression(model_type, num_of_features, model_parameters=tuned_parameters, x_header_size = x_train.shape[1])\n",
    "\n",
    "asc.train_and_save(model, model_type+'-model-tuned-tag', model_type\n",
    "                   , input_cols=header_x, target_col=header_y\n",
    "                   , x_train=x_train, y_train=y_train, scaler_option=scaler_option, path_to_save = '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning and show how it performs\n",
    "\n",
    "for model_type in ['RF','SVM','KR','BR','RF']:\n",
    "    tuned_parameters = asc.hyperparameter_tuning(model_type, x_train, y_train\n",
    "                                             , num_of_folds, scaler_option\n",
    "                                             , n_iter=2000, random_state=0, verbose=1)\n",
    "    # prediction with the tuned parameter\n",
    "    model = asc.define_model_regression(model_type, num_of_features, tuned_parameters, x_header_size = x_train.shape[1])\n",
    "    predictions, actual_values = asc.train_and_predict(model, x_train, y_train, scaler_option, num_of_folds=num_of_folds)\n",
    "    RMSE, R2 = asc.evaluate(predictions, actual_values)\n",
    "    print(\"* tuned (%s)\\t RMSE = %8.3f, R2 = %8.3f\"%(model_type, RMSE, R2))\n",
    "    asc.show_comparison_chart(predictions, actual_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "layer = 4\n",
    "params = [158, 1, 65, 179]\n",
    "dropout = 0.0119\n",
    "l_2 = 0.0481\n",
    "lr=0.000262\n",
    "epochs = 1000\n",
    "batch_size = 2\n",
    "num_of_folds = 5\n",
    "j = 0\n",
    "\n",
    "# Splitting the data for k-fold cross validation\n",
    "x_trains, y_trains, x_tests, y_tests = asc.split_data(x_train, y_train, num_of_folds=num_of_folds)\n",
    "\n",
    "# defining a model\n",
    "model = asc.net_define(params = params, layer_n = layer, input_size = x_trains[j].shape[1], dropout=dropout, l_2=l_2)\n",
    "model.summary()\n",
    "\n",
    "# choose your scaler\n",
    "scale = StandardScaler()\n",
    "x_train_ = scale.fit_transform(x_trains[j])\n",
    "\n",
    "# This is the change\n",
    "x_test_ = scale.transform(x_tests[j])\n",
    "\n",
    "# evaluating a model\n",
    "print('Training initiated ..')\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "score, history = asc.evaluate_net(model, epochs=epochs, batch_size=batch_size, x_train = x_train_, y_train = y_trains[0], x_test = x_test_, y_test = y_tests[0], verbose = 0, optimizer=optimizer)\n",
    "plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "plt.show()\n",
    "\n",
    "print('Model Test mean_absolute_percentage_error:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize the prediction\n",
    "asc.show_comparison_chart_model_x(model, x_test_, y_tests[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer = None\n",
    "params = None\n",
    "dropout = 0.0119\n",
    "l_2 = 0.0481\n",
    "lr = 0.000262\n",
    "epochs = 1000\n",
    "batch_size = 2\n",
    "num_of_folds = 5\n",
    "tries = 1000\n",
    "neuron_max = 256\n",
    "batch_size_max = 5\n",
    "layer_min = 4\n",
    "layer_max = 4\n",
    "dropout_max=0.02\n",
    "\n",
    "asc.net_tuning(tries = tries, lr = lr, x_trains = x_trains, y_trains = y_trains, x_tests = x_tests, y_tests = y_tests, layer = layer, params=params, epochs=epochs, batch_size=batch_size, dropout=dropout, l_2 = l_2, neuron_max=neuron_max, batch_size_max=batch_size_max, layer_min = layer_min, layer_max=layer_max, dropout_max=dropout_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
